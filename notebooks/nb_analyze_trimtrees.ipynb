{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results of tree trimming\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import umap\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from collections import * \n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "from ete4 import NCBITaxa, Tree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../repo-armbrust-metat-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.fn_metat_files as fnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/scratch/bgrodner/iron_ko_contigs'\n",
    "os.chdir(workdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_plot(\n",
    "    xlabel=\"\", ylabel=\"\", ft=12, dims=(5, 3), col=\"k\", lw=1, pad=0, tr_spines=True\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(dims[0], dims[1]), tight_layout={\"pad\": pad})\n",
    "    for i in ax.spines:\n",
    "        ax.spines[i].set_linewidth(lw)\n",
    "    if not tr_spines:\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "    else:\n",
    "        ax.spines[\"top\"].set_color(col)\n",
    "        ax.spines[\"right\"].set_color(col)\n",
    "    ax.spines[\"bottom\"].set_color(col)\n",
    "    ax.spines[\"left\"].set_color(col)\n",
    "    ax.tick_params(direction=\"in\", labelsize=ft, color=col, labelcolor=col)\n",
    "    ax.set_xlabel(xlabel, fontsize=ft, color=col)\n",
    "    ax.set_ylabel(ylabel, fontsize=ft, color=col)\n",
    "    ax.patch.set_alpha(0)\n",
    "    return (fig, ax)\n",
    "\n",
    "def plot_umap(\n",
    "    embedding,\n",
    "    figsize=(10, 10),\n",
    "    markersize=10,\n",
    "    alpha=0.5,\n",
    "    colors=\"k\",\n",
    "    xticks=[],\n",
    "    yticks=[],\n",
    "    markerstyle='o',\n",
    "    cmap_name='tab20',\n",
    "    cl_lab=False\n",
    "):\n",
    "    fig, ax = general_plot(dims=figsize)\n",
    "    if isinstance(markerstyle, str):\n",
    "        ax.scatter(\n",
    "            embedding[:, 0],\n",
    "            embedding[:, 1],\n",
    "            s=markersize,\n",
    "            alpha=alpha,\n",
    "            c=colors,\n",
    "            edgecolors=\"none\",\n",
    "            marker=markerstyle,\n",
    "            cmap=cmap_name\n",
    "        )\n",
    "    else:\n",
    "        for e0, e1, c, m in zip(\n",
    "            embedding[:, 0], \n",
    "            embedding[:, 1],\n",
    "            colors,\n",
    "            markerstyle \n",
    "        ):\n",
    "            ax.scatter(\n",
    "                e0,\n",
    "                e1,\n",
    "                s=markersize,\n",
    "                alpha=alpha,\n",
    "                c=c,\n",
    "                edgecolors=\"none\",\n",
    "                marker=m\n",
    "            )\n",
    "    ax.set_aspect(\"equal\")\n",
    "    if len(xticks) > 0:\n",
    "        ax.set_xticks(xticks)\n",
    "    if len(yticks) > 0:\n",
    "        ax.set_yticks(yticks)\n",
    "    ax.set_xlabel(\"UMAP 1\")\n",
    "    ax.set_ylabel(\"UMAP 2\")\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get KO dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_fn = \"ko00001.json\"\n",
    "database = list()\n",
    "for _, v in pd.read_json(ko_fn).iterrows():\n",
    "    d = v[\"children\"]\n",
    "    cat_1 = d[\"name\"]\n",
    "    for child_1 in d[\"children\"]:\n",
    "        cat_2 = child_1[\"name\"] # Module?\n",
    "        for child_2 in child_1[\"children\"]:\n",
    "            cat_3 = child_2[\"name\"]\n",
    "            if \"children\" in child_2:\n",
    "                for child_3 in child_2[\"children\"]:\n",
    "                    cat_4 = child_3[\"name\"]\n",
    "                    fields = [cat_1, cat_2, cat_3, cat_4]\n",
    "                    database.append(fields)\n",
    "df_kegg = pd.DataFrame(database, columns=[\"Level_A\", \"Level_B\", \"Level_C\", \"Level_D\"])\n",
    "df_kegg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = df_kegg['Level_D'].values\n",
    "ld[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_name = {}\n",
    "for name in ld:\n",
    "    ko = re.search(r\"^\\w+\",name)[0]\n",
    "    dict_ko_name[ko] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G1PA filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ko_dict = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig'\n",
    "fn_dict_ko_contigs = f'{dir_ko_dict}/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-dict.json'\n",
    "\n",
    "fn_dict_taxtrim_contigs = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tidys/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-dict_taxtrim_contigs.json'\n",
    "\n",
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count'\n",
    "glob_fn = f'{dir_counts}/*G1PA*.json'\n",
    "fns = glob.glob(glob_fn)\n",
    "\n",
    "fn_dict_contig_taxon = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_tax/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-dict_contig_taxid.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load estcounts ordered by sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig_estcounts = defaultdict(list)\n",
    "for fn in fns:\n",
    "    # Load counts\n",
    "    with open(fn, 'r') as f:\n",
    "        dict_ctg_cnt = json.load(f)\n",
    "    for ctg, cnt in dict_ctg_cnt.items():\n",
    "        # map contig to counts\n",
    "        dict_contig_estcounts[ctg].append(float(cnt[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ko contigs and get inverted dict and rework contig from 6tr format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_dict_ko_contigs, 'r') as f:\n",
    "    dict_ko_contigs = json.load(f)\n",
    "\n",
    "dict_contig_ko = {}\n",
    "dict_ko_contigs_new = defaultdict(list)\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    for c in contigs:\n",
    "        c_ = re.sub(r'_\\d+$','',c)\n",
    "        dict_ko_contigs_new[ko].append(c_)\n",
    "        dict_contig_ko[c_] = ko\n",
    "dict_ko_contigs = dict_ko_contigs_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load taxtrim contigs and undo 6tr and get inverted dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_dict_taxtrim_contigs, 'r') as f:\n",
    "    dict_taxtrim_contigs = json.load(f)\n",
    "\n",
    "dict_taxtrim_contigs_new = defaultdict(list)\n",
    "dict_contig_taxtrim = {}\n",
    "for tid, contigs in dict_taxtrim_contigs.items():\n",
    "    for c in contigs:\n",
    "        c_ = re.sub(r'_\\d+$','',c)\n",
    "        dict_taxtrim_contigs_new[tid].append(c_)\n",
    "        dict_contig_taxtrim[c_] = tid\n",
    "\n",
    "dict_taxtrim_contigs = dict_taxtrim_contigs_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load untrimmed taxa and undo 6tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_dict_contig_taxon, 'r') as f:\n",
    "    dict_contig_taxon = json.load(f)\n",
    "\n",
    "dict_contig_taxon_new= {}\n",
    "for c, tid in dict_contig_taxon.items():\n",
    "    c_ = re.sub(r'_\\d+$','',c)\n",
    "    dict_contig_taxon_new[c_] = tid\n",
    "\n",
    "dict_contig_taxon = dict_contig_taxon_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for fn in fns:\n",
    "    samples.append(re.search(r'(?<=\\.tar\\.gz\\.).+(?=\\.tsv-)', fn)[0])\n",
    "samples[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fn = '/scratch/bgrodner/repo-armbrust-metat/gradients1/g1_station_pa_metat/sample_metadata.csv'\n",
    "meta = pd.read_csv(meta_fn)\n",
    "df_meta = []\n",
    "for s in samples:\n",
    "    sid = re.search(r\"(?<=G1PA\\.).+(?=\\.abundance)\", s)[0]\n",
    "    sid = re.sub('\\.','_',sid)\n",
    "    row = meta[meta['SampleID'] == sid].squeeze()\n",
    "    df_meta.append(row)\n",
    "df_meta = pd.DataFrame(df_meta, index=samples)\n",
    "df_meta[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many KOs, contigs, taxa, samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "There are \n",
    "    {len(dict_ko_contigs)} KOs \n",
    "    {len(dict_taxtrim_contigs)} taxa\n",
    "    {len(dict_contig_estcounts):,} contigs\n",
    "    {len(next(iter(dict_contig_estcounts.values())))} samples\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many taxon-ko pairs are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_taxon_pairs = set()\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    for c in contigs:\n",
    "        tax = dict_contig_taxtrim.get(c)\n",
    "        if tax:\n",
    "            ko_taxon_pairs.add(f'{ko}-{tax}')\n",
    "print(f\"\"\"\n",
    "There are \n",
    "    {len(ko_taxon_pairs)} KO-taxon pairs \n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "There are\n",
    "    Depths:\\t{df_meta['Depth'].unique()}\n",
    "    Filter:\\t{df_meta['Filter'].unique()}\n",
    "    Latitude:\\t{[float(round(l,2)) for l in df_meta['Latitude'].sort_values().unique()]}\n",
    "    Longitude:\\t{[float(round(l,2)) for l in df_meta['Longitude'].sort_values().unique()]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples is each KO in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_nsams = {}\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    sams = np.zeros(len(samples))\n",
    "    for c in contigs:\n",
    "        sams += dict_contig_estcounts[c]\n",
    "    dict_ko_nsams[ko] = sams.astype(bool).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_ko_nsams.values()))\n",
    "_ = ax.set_xlabel('Number of samples a KO is in')\n",
    "_ = ax.set_ylabel('Number KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many taxa is each KO in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_ntax = {}\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    taxa = set()\n",
    "    for c in contigs:\n",
    "        tid = dict_contig_taxtrim.get(c)\n",
    "        if tid:\n",
    "            taxa.add(tid)\n",
    "    dict_ko_ntax[ko] = len(taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_ko_ntax.values()))\n",
    "_ = ax.set_xlabel('Number of taxa a KO is in')\n",
    "_ = ax.set_ylabel('Number KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples is each taxon in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_nsams = {}\n",
    "for tax, contigs in dict_taxtrim_contigs.items():\n",
    "    sams = np.zeros(len(samples))\n",
    "    for c in contigs:\n",
    "        sams += dict_contig_estcounts[c]\n",
    "    dict_tax_nsams[tax] = sams.astype(bool).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_tax_nsams.values()))\n",
    "_ = ax.set_xlabel('Number of samples a taxon is in')\n",
    "_ = ax.set_ylabel('Number taxa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many KOs does each taxon have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_nkos = {}\n",
    "for tax, contigs in dict_taxtrim_contigs.items():\n",
    "    kos = set()\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko.get(c)\n",
    "        if ko:\n",
    "            kos.add(ko)\n",
    "    dict_tax_nkos[tax] = len(kos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_tax_nkos.values()), bins=20)\n",
    "_ = ax.set_xlabel('Number of KOs in a taxon')\n",
    "_ = ax.set_ylabel('Number taxa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples is each KO in each taxon in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_tax_estcounts = defaultdict(lambda: defaultdict(lambda: np.zeros(len(samples))))\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    for c in contigs:\n",
    "        tax = dict_contig_taxtrim.get(c)\n",
    "        if tax:\n",
    "            dict_ko_tax_estcounts[ko][tax] += dict_contig_estcounts[c]\n",
    "kotax_nsams = []\n",
    "for ko, d in dict_ko_tax_estcounts.items():\n",
    "    for tax, ec in d.items():\n",
    "        kotax_nsams.append(ec.astype(bool).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(kotax_nsams, bins=20)\n",
    "_ = ax.set_xlabel('Number of samples a KO in a givern taxon is in')\n",
    "_ = ax.set_ylabel('Number KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect interesting subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which KOs are not in all the samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ko, nsams in dict_ko_nsams.items():\n",
    "    if nsams < 20:\n",
    "        print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which KOs are in many taxa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ko, ntax in dict_ko_ntax.items():\n",
    "    if ntax > 60:\n",
    "        print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which taxa are not in all the samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tax, nsams in dict_tax_nsams.items():\n",
    "    if nsams < 47:\n",
    "        print(ncbi.get_taxid_translator([tax]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which taxa have lots of KOs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tax, nkos in dict_tax_nkos.items():\n",
    "    if nkos > 90:\n",
    "        print(ncbi.get_taxid_translator([tax]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare bacteria and eukaryotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict defining each taxon as bacteria or eukaryote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_taxtrim_bacteuk = {}\n",
    "for tax, _ in dict_taxtrim_contigs.items():\n",
    "    lineage = ncbi.get_lineage(tax)\n",
    "    if 2759 in lineage:\n",
    "        dict_taxtrim_bacteuk[tax] = 'Eukaryota'\n",
    "    elif 2 in lineage:\n",
    "        dict_taxtrim_bacteuk[tax] = 'Bacteria'\n",
    "    else:\n",
    "        dict_taxtrim_bacteuk[tax] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bacterial vs eukaryota KOs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_ebs = {}\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    ebs = set()\n",
    "    for c in contigs:\n",
    "        tax = dict_contig_taxtrim.get(c)\n",
    "        if tax:\n",
    "            eb = dict_taxtrim_bacteuk[tax]\n",
    "            ebs.add(eb)\n",
    "    if ebs:\n",
    "        dict_ko_ebs[ko] = ', '.join(str(x) for x in ebs)\n",
    "    else:\n",
    "        dict_ko_ebs[ko] = 'none'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, counts = np.unique(list(dict_ko_ebs.values()), return_counts=True)\n",
    "\n",
    "fig, ax = general_plot()\n",
    "_ = ax.bar(names, counts)\n",
    "_ = ax.set_ylabel('Number KOs')\n",
    "_ = ax.set_xticklabels(names,rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which KOs are only in bacteria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ko, ebs, in dict_ko_ebs.items():\n",
    "    if (ebs == 'Bacteria') | (ebs == 'other, Bacteria'):\n",
    "        print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which KOs are Eukariota and bacteria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ko, ebs, in dict_ko_ebs.items():\n",
    "    if (ebs == 'Eukaryota, Bacteria'):\n",
    "        print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which taxa are the siderophore KOs in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K04792','K15721','K22736']\n",
    "dict_kotarget_taxa = defaultdict(set)\n",
    "for ko in kos:\n",
    "    contigs = dict_ko_contigs[ko]\n",
    "    for c in contigs:\n",
    "        tax = dict_contig_taxtrim.get(c)\n",
    "        if tax:\n",
    "            dict_kotarget_taxa[ko].add(tax)\n",
    "\n",
    "for ko, taxa in dict_kotarget_taxa.items():\n",
    "    print(dict_ko_name[ko])\n",
    "    for tid in taxa:\n",
    "        print(f'\\t{ncbi.get_taxid_translator([tid])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which taxa (untrimmed?) are the siderophore KOs in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K04792','K15721','K22736']\n",
    "dict_kotarget_taxa = defaultdict(set)\n",
    "for ko in kos:\n",
    "    contigs = dict_ko_contigs[ko]\n",
    "    for c in contigs:\n",
    "        tax = dict_contig_taxon.get(c)[0]\n",
    "        if tax:\n",
    "            dict_kotarget_taxa[ko].add(tax)\n",
    "\n",
    "for ko, taxa in dict_kotarget_taxa.items():\n",
    "    print(dict_ko_name[ko])\n",
    "    for tid in taxa:\n",
    "        print(f'\\t{ncbi.get_taxid_translator([tid])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming distances between ko-taxon pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_kotax = []\n",
    "index_kotax = []\n",
    "for ko, d in dict_ko_tax_estcounts.items():\n",
    "    for tax, ec in d.items():\n",
    "        index_kotax.append(f\"{ko}-{tax}\")\n",
    "        arr_kotax.append(ec.astype(bool))\n",
    "arr_kotax = np.array(arr_kotax)\n",
    "arr_kotax.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP on array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 7\n",
    "reducer = umap.UMAP(metric='hamming', n_neighbors=nn)\n",
    "embedding = reducer.fit_transform(arr_kotax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (5,5)\n",
    "alpha = 0.1\n",
    "fig, ax = general_plot(dims=dims)\n",
    "_ = ax.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    alpha=alpha\n",
    ")\n",
    "_ = ax.set_aspect('equal','datalim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster ko-taxon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = distance.pdist(arr_kotax, metric='hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = hierarchy.linkage(dists, method='centroid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "dn = hierarchy.dendrogram(link, truncate_mode='lastp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.2\n",
    "clust_hier = hierarchy.fcluster(link, t=t, criterion='distance')\n",
    "# nclust = 6\n",
    "# clust_hier = hierarchy.fcluster(link, t=nclust, criterion='maxclust')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (5,5)\n",
    "alpha = 0.1\n",
    "fig, ax = general_plot(dims=dims)\n",
    "_ = ax.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    alpha=alpha,\n",
    "    c=clust_hier,\n",
    "    cmap='tab10'\n",
    ")\n",
    "_ = ax.set_aspect('equal','datalim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clust_hier, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_square = distance.squareform(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_agg_fit = cluster.AgglomerativeClustering(metric='precomputed', linkage='complete').fit(dists_square)\n",
    "clust_agg = clust_agg_fit.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clust_agg, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (5,5)\n",
    "alpha = 0.1\n",
    "fig, ax = general_plot(dims=dims)\n",
    "_ = ax.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    alpha=alpha,\n",
    "    c=clust_agg,\n",
    "    cmap='tab10'\n",
    ")\n",
    "_ = ax.set_aspect('equal','datalim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the distribution across samples for each cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = []\n",
    "clusts = np.unique(clust_agg)\n",
    "for cl in clusts:\n",
    "    col = arr_kotax[clust_agg == cl].mean(axis=0).squeeze()\n",
    "    cl_df.append(col)\n",
    "\n",
    "pd.DataFrame(np.array(cl_df).T, columns=clusts, index=samples).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So seemingly ^ cluster 1 is just ko-taxon pairs with fewer samples and cluster 0 is those with all or almost all the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find groups of taxon-ko pairs with very small hamming distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the metric for 1, 2, 3 disagreements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i, i / len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 1 disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.03\n",
    "clust_hier = hierarchy.fcluster(link, t=t, criterion='distance')\n",
    "clusts, counts = np.unique(clust_hier, return_counts=True)\n",
    "print(counts[counts > 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the big cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "clids = clusts[counts >= 310]\n",
    "clids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clid in clids:\n",
    "    bool_ind = (clust_hier == clid)\n",
    "    inds = np.array(index_kotax)[bool_ind]\n",
    "    arr_sub = arr_kotax[bool_ind]\n",
    "    print(arr_sub.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ This is the ko-taxa that are present across almost all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the next biggest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "clids = clusts[counts == 31]\n",
    "clids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clid in clids:\n",
    "    bool_ind = (clust_hier == clid)\n",
    "    inds = np.array(index_kotax)[bool_ind]\n",
    "    arr_sub = arr_kotax[bool_ind]\n",
    "    print(arr_sub.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ this is the almost empty pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at some other clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "clids = clusts[(counts > 10) & (counts < 30)]\n",
    "clids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clid in clids:\n",
    "    bool_ind = (clust_hier == clid)\n",
    "    inds = np.array(index_kotax)[bool_ind]\n",
    "    arr_sub = arr_kotax[bool_ind]\n",
    "    print(clid)\n",
    "    print(arr_sub.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ this is mixed some are interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 2 disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.05\n",
    "clust_hier = hierarchy.fcluster(link, t=t, criterion='distance')\n",
    "clusts, counts = np.unique(clust_hier, return_counts=True)\n",
    "print(counts[counts > 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get those with count greater than three and present in a moderate number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl, cnt in zip(clusts, counts):\n",
    "    if cnt > 3:\n",
    "        bool_ind = (clust_hier == cl)\n",
    "        arr_sub = arr_kotax[bool_ind]\n",
    "        mn = arr_sub.mean(axis=0)\n",
    "        npos = sum(mn > 0.5)\n",
    "        if (npos > 3) & (npos < 10):\n",
    "            print('\\n\\n',cl, '\\n', mn)\n",
    "\n",
    "            inds = np.array(index_kotax)[bool_ind]\n",
    "            dict_tk = defaultdict(list)\n",
    "            for kotax in inds:\n",
    "                ko, tax = kotax.split('-')\n",
    "                t = list(ncbi.get_taxid_translator([tax]).values())[0]\n",
    "                k = dict_ko_name[ko]\n",
    "                dict_tk[t].append(k)\n",
    "            for t, ks in dict_tk.items():\n",
    "                print('\\t', t)\n",
    "                for k in ks:\n",
    "                    print('\\t\\t',k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged samples tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-barnacle_tensor_tidy.csv'\n",
    "# fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_9_minbatches_4.csv'\n",
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which csv reader is fastest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    t0 = time()\n",
    "    for i in range(10000):\n",
    "        row = next(f)\n",
    "        row = row.split(',')\n",
    "        sample = row[0]\n",
    "    t1 = time()\n",
    "print(f\"{(t1-t0) // 60} min {(t1-t0) % 60} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    t0 = time()\n",
    "    for i in range(10000):\n",
    "        row = next(reader)\n",
    "        sample = row[0]\n",
    "    t1 = time()\n",
    "print(f\"{(t1-t0) // 60} min {(t1-t0) % 60} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    t0 = time()\n",
    "    for i in range(10000):\n",
    "        row = next(reader)\n",
    "        sample = row['assm_sample']\n",
    "    t1 = time()\n",
    "print(f\"{(t1-t0) // 60} min {(t1-t0) % 60} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_taxtrim_ko_sample_estcounts = defaultdict(\n",
    "    lambda: defaultdict(dict)\n",
    ")\n",
    "i = 0\n",
    "with open(fn_tensor, 'r') as f:\n",
    "    _ = next(f)\n",
    "    for row in f:\n",
    "        i += 1\n",
    "        sample, ko, tax, estcounts, rep = row.split(',')\n",
    "        sam = f\"{sample}-{rep}\"\n",
    "        dict_taxtrim_ko_sample_estcounts[tax][ko][sam] = float(estcounts)\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many KOs, contigs, taxa, samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_all = set()\n",
    "kos_all = set()\n",
    "samples_all = set()\n",
    "taxko_all = set()\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "  taxa_all.add(tax)\n",
    "  for ko, dse in dkse.items():\n",
    "    taxko_all.add(f\"{tax}-{ko}\")\n",
    "    kos_all.add(ko)\n",
    "    for sam, ec in dse.items():\n",
    "      samples_all.add(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "There are \n",
    "    {len(kos_all)} KOs \n",
    "    {len(taxa_all)} taxa\n",
    "    {len(samples_all)} samples\n",
    "    {len(taxko_all)} taxon-kos\n",
    "    {len(kos_all)*len(taxa_all)*len(samples_all):,d} total cells\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ncbi.get_topology(taxa_all)\n",
    "for n in tree.traverse():\n",
    "    if str(n.name) in taxa_all:\n",
    "        kos = list(dict_taxtrim_ko_sample_estcounts[n.name].keys())\n",
    "        nkos = len(kos)\n",
    "    else:\n",
    "        nkos = 'NA'\n",
    "    n.add_props(\n",
    "        nkos=nkos\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.to_str(props=['sci_name','name','nkos'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples is each KO in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_sam_ec = defaultdict(lambda: defaultdict(float))\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "    for ko, dse in dkse.items():\n",
    "        for sam, ec in dse.items():\n",
    "            dict_ko_sam_ec[ko][sam] += ec\n",
    "dict_ko_nsams = {}\n",
    "for ko, dse in dict_ko_sam_ec.items():\n",
    "    nsam = 0\n",
    "    for sam, ec in dse.items():\n",
    "        if ec:\n",
    "            nsam += 1\n",
    "    dict_ko_nsams[ko] = nsam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_ko_nsams.values()))\n",
    "_ = ax.set_xlabel('Number of samples a KO is in')\n",
    "_ = ax.set_ylabel('Number KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many taxa is each KO in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_taxa = defaultdict(list)\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "    for ko, dse in dkse.items():\n",
    "        dict_ko_taxa[ko].append(tax)\n",
    "\n",
    "dict_ko_ntax = {}\n",
    "for ko, taxa in dict_ko_taxa.items():\n",
    "    dict_ko_ntax[ko] = len(taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_ko_ntax.values()), bins=15)\n",
    "_ = ax.set_xlabel('Number of taxa a KO is in')\n",
    "_ = ax.set_ylabel('Number KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples is each taxon in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_sam_ec = defaultdict(lambda: defaultdict(float))\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "    for ko, dse in dkse.items():\n",
    "        for sam, ec in dse.items():\n",
    "            dict_tax_sam_ec[tax][sam] += ec\n",
    "dict_tax_nsams = {}\n",
    "for tax, dse in dict_tax_sam_ec.items():\n",
    "    nsam = 0\n",
    "    for sam, ec in dse.items():\n",
    "        if ec:\n",
    "            nsam += 1\n",
    "    dict_tax_nsams[tax] = nsam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_tax_nsams.values()), bins=20)\n",
    "_ = ax.set_xlabel('Number of samples a taxon is in')\n",
    "_ = ax.set_ylabel('Number taxa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many KOs does each taxon have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_nkos = {}\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "    dict_tax_nkos[tax] = len(dkse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_tax_nkos.values()), bins=20)\n",
    "_ = ax.set_xlabel('Number of KOs in a taxon')\n",
    "_ = ax.set_ylabel('Number taxa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples is each KO in each taxon in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_taxko_sam_ec = defaultdict(lambda: defaultdict(float))\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "    for ko, dse in dkse.items():\n",
    "        taxko = f\"{tax}-{ko}\"\n",
    "        for sam, ec in dse.items():\n",
    "            dict_taxko_sam_ec[taxko][sam] += ec\n",
    "dict_taxko_nsams = {}\n",
    "for taxko, dse in dict_taxko_sam_ec.items():\n",
    "    nsam = 0\n",
    "    for sam, ec in dse.items():\n",
    "        if ec:\n",
    "            nsam += 1\n",
    "    dict_taxko_nsams[taxko] = nsam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "_ = ax.hist(list(dict_taxko_nsams.values()), bins=100)\n",
    "_ = ax.set_xlabel('Number of samples a KO in a givern taxon is in')\n",
    "_ = ax.set_ylabel('Number KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare bacteria and eukaryotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict defining each taxon as bacteria or eukaryote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_taxtrim_bacteuk = {}\n",
    "for tax in taxa_all:\n",
    "    lineage = ncbi.get_lineage(tax)\n",
    "    if 2759 in lineage:\n",
    "        dict_taxtrim_bacteuk[tax] = 'Eukaryota'\n",
    "    elif 2 in lineage:\n",
    "        dict_taxtrim_bacteuk[tax] = 'Bacteria'\n",
    "    else:\n",
    "        dict_taxtrim_bacteuk[tax] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bacterial vs eukaryota KOs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_ebsset = defaultdict(set)\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "    for ko, _ in dkse.items():\n",
    "        eb = dict_taxtrim_bacteuk[tax]\n",
    "        dict_ko_ebsset[ko].add(eb)\n",
    "\n",
    "dict_ko_ebs = {}\n",
    "for ko, ebs in dict_ko_ebsset.items():\n",
    "    if ebs:\n",
    "        dict_ko_ebs[ko] = ', '.join(str(x) for x in ebs)\n",
    "    else:\n",
    "        dict_ko_ebs[ko] = 'none'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, counts = np.unique(list(dict_ko_ebs.values()), return_counts=True)\n",
    "\n",
    "fig, ax = general_plot()\n",
    "_ = ax.bar(names, counts)\n",
    "_ = ax.set_ylabel('Number KOs')\n",
    "_ = ax.set_xticklabels(names,rotation=45, ha='right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which KOs are only in bacteria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ko, ebs, in dict_ko_ebs.items():\n",
    "    if (ebs == 'Bacteria'):\n",
    "        print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which KOs are only in eukaryota?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ko, ebs, in dict_ko_ebs.items():\n",
    "    if (ebs == 'Eukaryota'):\n",
    "        print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a tensor with only a few taxa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-barnacle_tensor_tidy.csv'\n",
    "\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = \"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-barnacle_tensor_tidy-subset_taxa_01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species, taxid, nkos\n",
    "nodes_sub_01 = [\n",
    "    \"Pelagomonadales,54409,211\",\n",
    "    \"Thalassiosirales,33847,234\",\n",
    "    \"Pseudomonadota,1224,326\"\n",
    "]\n",
    "\n",
    "nodes_sub_02 = [\n",
    "    \"Pelagomonadales,54409,211\",\n",
    "    \"Thalassiosirales,33847,234\",\n",
    "    \"Pseudomonadota,1224,326\",\n",
    "    \"Pelagomonas calceolata,35677,252\",\n",
    "    \"Bacillati,1783272,288\",\n",
    "    \"Micromonas,38832,226\",\n",
    "]\n",
    "\n",
    "nodes_sub_03 = [\n",
    "    \"Pelagomonadales,54409,211\",\n",
    "    \"Thalassiosirales,33847,234\",\n",
    "    \"Pseudomonadota,1224,326\",\n",
    "    \"Pelagomonas calceolata,35677,252\",\n",
    "    \"Bacillati,1783272,288\",\n",
    "    \"Micromonas,38832,226\",\n",
    "    \"Pseudomonadati,3379134,298\",\n",
    "    \"Bacteria,2,298\",\n",
    "    \"Karlodinium veneficum,407301,243\",\n",
    "    \"Karenia brevis,156230,203\",\n",
    "    \"Symbiodiniaceae,252141,265\",\n",
    "    \"Pelagodinium beii,43686,221\",\n",
    "]\n",
    "\n",
    "taxa_sub = []\n",
    "# for t in nodes_sub_01:\n",
    "for t in nodes_sub_03:\n",
    "    _, tid, _ = t.split(',')\n",
    "    taxa_sub.append(tid)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_ko_name['K08906'])\n",
    "\n",
    "taxa = [54409, 1224]\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = [\n",
    "    'K22341', 'K00532'\n",
    "]\n",
    "for ko in kos:\n",
    "    print(dict_ko_name[ko])\n",
    "\n",
    "taxa = [\n",
    "    '33847', '1224'\n",
    "]\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtn = {\n",
    "    '54409' : \"Pelagomonadales\",\n",
    "    '33847' : \"Thalassiosirales\",\n",
    "    '1224' : \"Pseudomonadota\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = [\n",
    "    'K00216', 'K00362', 'K02364', 'K03839', 'K03840', 'K07243', 'K11532',\n",
    "       'K12239', 'K14690', 'K17877', 'K21990'\n",
    "]\n",
    "dkn = {}\n",
    "for k in kos:\n",
    "    dkn[k] = dict_ko_name[k]\n",
    "dkn    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset batches in taxon subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = \"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-barnacle_tensor_tidy-subset_taxa_03-subset_batches_01.csv\"\n",
    "# fn_tensor_sub = \"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-barnacle_tensor_tidy-subset_taxa_01-subset_batches_01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of batches to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species, taxid, nkos\n",
    "batches_sub_01 = [\n",
    "    \"D1PA\",\n",
    "    \"G1PA\",\n",
    "    \"G2PA\",\n",
    "    \"G3PA\"\n",
    "]\n",
    "batches_sub_02 = [\n",
    "    \"D1PA\",\n",
    "    \"G1PA\",\n",
    "    \"G2PA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_meta = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-metadata.csv'\n",
    "metadata = pd.read_csv(fn_meta)\n",
    "metadata[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict mapping assm sample to batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_assmsam_batch = dict(zip(\n",
    "    metadata['assm_sample'],\n",
    "    metadata['assembly']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)  # Write header\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, _, tax, _, _ = row.split(\",\")\n",
    "        bool_batch = (dict_assmsam_batch[sample] in batches_sub_01)\n",
    "        bool_tax = (tax in taxa_sub)\n",
    "        if bool_batch & bool_tax:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub taxa 03, sub batches 01: Find component 1 latitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K07214', 'K02641', 'K02639', 'K00927', 'K03320']\n",
    "taxa = ['35677', '2', '3379134']\n",
    "samples = ['G3PA-UW32-7-3.0', 'G3PA-UW31#2-7-3.0', 'G2PA-S17C1-15m-3um', 'G3PA-UW32#3-7-3.0', 'G3PA-UW25-7-3.0', 'G2PA-S02C1-15m-3um', 'G2PA-S07C1-15m-3um', 'G1PA-S02C1-3um', 'G1PA-S14C1-3um', 'G3PA-UW40-7-3.0', 'G2PA-S18C1-15m-3um', 'G2PA-S11C1-15m-3um', 'G3PA-UW29-7-3.0', 'G2PA-S06C1-15m-3um', 'D1PA-S33C1-1800', 'G1PA-S13C1-3um', 'G3PA-UW35#2-7-3.0', 'D1PA-S35C1-200', 'G2PA-S15C1-15m-3um', 'G2PA-S16C1-15m-3um']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata.assembly == 'G3PA'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_sams = []\n",
    "for s in samples:\n",
    "    assm, sam = s.split('-')[:2]\n",
    "    bool_a = metadata['assembly'] == assm\n",
    "    bool_s = metadata['sample'] == sam\n",
    "    row = metadata[bool_a & bool_s]\n",
    "    print(s, row.latitude.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a G3NS tensor with only a few taxa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = \"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/G3NS_kofam2021_ALL.csv-iron_KOs.txt-tidys/G3NS_kofam2021_ALL.csv-iron_KOs.txt-barnacle_tensor_tidy.csv\"\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_taxtrim_ko_sample_estcounts = defaultdict(\n",
    "    lambda: defaultdict(dict)\n",
    ")\n",
    "i = 0\n",
    "with open(fn_tensor, 'r') as f:\n",
    "    _ = next(f)\n",
    "    for row in f:\n",
    "        i += 1\n",
    "        sample, ko, tax, estcounts, rep = row.split(',')\n",
    "        sam = f\"{sample}-{rep}\"\n",
    "        dict_taxtrim_ko_sample_estcounts[tax][ko][sam] = float(estcounts)\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many KOs, contigs, taxa, samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_all = set()\n",
    "kos_all = set()\n",
    "samples_all = set()\n",
    "taxko_all = set()\n",
    "for tax, dkse in dict_taxtrim_ko_sample_estcounts.items():\n",
    "  taxa_all.add(tax)\n",
    "  for ko, dse in dkse.items():\n",
    "    taxko_all.add(f\"{tax}-{ko}\")\n",
    "    kos_all.add(ko)\n",
    "    for sam, ec in dse.items():\n",
    "      samples_all.add(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "There are \n",
    "    {len(kos_all)} KOs \n",
    "    {len(taxa_all)} taxa\n",
    "    {len(samples_all)} samples\n",
    "    {len(taxko_all)} taxon-kos\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ncbi.get_topology(taxa_all)\n",
    "for n in tree.traverse():\n",
    "    if str(n.name) in taxa_all:\n",
    "        kos = list(dict_taxtrim_ko_sample_estcounts[n.name].keys())\n",
    "        nkos = len(kos)\n",
    "    else:\n",
    "        nkos = 'NA'\n",
    "    n.add_props(\n",
    "        nkos=nkos\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.to_str(props=['sci_name','name','nkos'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 taxa\n",
    "\n",
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = \"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/G3NS_kofam2021_ALL.csv-iron_KOs.txt-tidys/G3NS_kofam2021_ALL.csv-iron_KOs.txt-barnacle_tensor_tidy-sub_taxa_01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species, taxid, nkos\n",
    "nodes_sub_01 = [\n",
    "    \"Pseudoalteromonas sp. '520P1 No. 412',304208,47\",\n",
    "    \"Alteromonas,226,86\",\n",
    "    \"Roseobacteraceae,2854170,45\",\n",
    "    \"Paracoccaceae,31989,52\",\n",
    "    \"Pelagomonas calceolata,35677,134\",\n",
    "    \"Thalassiosira,35127,42\",\n",
    "    \"Stramenopiles MAST-4,1735725,60\",\n",
    "]\n",
    "\n",
    "\n",
    "taxa_sub = []\n",
    "for t in nodes_sub_01:\n",
    "    _, tid, _ = t.split(',')\n",
    "    taxa_sub.append(tid)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14 taxa\n",
    "\n",
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = \"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/G3NS_kofam2021_ALL.csv-iron_KOs.txt-tidys/G3NS_kofam2021_ALL.csv-iron_KOs.txt-barnacle_tensor_tidy-sub_taxa_02.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species, taxid, nkos\n",
    "nodes_sub_01 = [\n",
    "    \"Pseudoalteromonas sp. '520P1 No. 412',304208,47\",\n",
    "    \"Alteromonas,226,86\",\n",
    "    \"Roseobacteraceae,2854170,45\",\n",
    "    \"Paracoccaceae,31989,52\",\n",
    "    \"Pelagomonas calceolata,35677,134\",\n",
    "    \"Thalassiosira,35127,42\",\n",
    "    \"Stramenopiles MAST-4,1735725,60\",\n",
    "    \"Flavobacteriaceae,49546,139\",\n",
    "    \"Flavobacteria bacterium MS024-2A,487796,61\",\n",
    "    \"Alphaproteobacteria,28211,143\",\n",
    "    \"Vibrionales,135623,158\",\n",
    "    \"Dinophyceae,2864,225\",\n",
    "    \"Chlorophyta,3041,80\",\n",
    "    \"Ochrophyta,2696291,167\"\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "taxa_sub = []\n",
    "for t in nodes_sub_01:\n",
    "    _, tid, _ = t.split(',')\n",
    "    taxa_sub.append(tid)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa = [      2,     976,    2759,   49546, 2696291,  131567,    2864,\n",
    "         35677,    1236,   33313,   78238,    3041,    2916,    2836,\n",
    "        200644, 2698737,   35675,   33656,  135623,   28211]\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa = ['35677', '31989', '226', '304208']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K02722', 'K00372' ,'K07214', 'K02691', 'K00855', 'K02709']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa = ['35677', '226','35127']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K00532', 'K06441', 'K22338', 'K02705', 'K22341', 'K10850', 'K00372', 'K02598', 'K01602', 'K02567', 'K02709']\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxa = ['1735725', '31989', '226', '35127']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K00368', 'K16087', 'K22552', 'K02567', 'K19611', 'K04565']\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxa = ['35127', '226', '304208', '1735725']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K07214', 'K23723', 'K10850', 'K07243', 'K01595', 'K00855']\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxa = ['135623', '28211', '49546', '2864']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K03320', 'K00362']\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['G3.UW.NS-UW32-32.93-3.7m-0.2um', 'G3.UW.NS-UW29-29.46-1.7m-0.2um', 'G3.UW.NS-UW25-25.87-1.7m-0.2um', 'G3.UW.NS-UW32-32.93-3.7m-3um', 'G3.UW.NS-UW31-31.43-2.7m-3um', 'G3.UW.NS-UW35-35.83-2.7m-0.2um', 'G3.UW.NS-UW32-32.3-1.7m-3um', 'G3.UW.NS-UW32-32.3-1.7m-0.2um', 'G3.UW.NS-UW37-37.0-1.7m-0.2um', 'G3.UW.NS-UW35-35.83-2.7m-3um']\n",
    "lats = []\n",
    "infos = []\n",
    "for s in samples:\n",
    "    assm, sam, lat, depth, size = s.split('-')\n",
    "    lats.append(lat)\n",
    "    infos.append(f\"{lat}-{depth}-{size}\")\n",
    "\n",
    "# [x for _, x in sorted(zip(lats, infos))]\n",
    "infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxa = ['487796', '226', '49546', '2696291', '3041']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K19611', 'K06503', 'K00264', 'K01851', 'K00265', 'K16090', 'K25224', 'K00615', 'K00134', 'K03832']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['G3.UW.NS-UW32-32.93-3.7m-0.2um', 'G3.UW.NS-UW32-32.3-1.7m-0.2um', 'G3.UW.NS-UW29-29.46-1.7m-0.2um', 'G3.UW.NS-UW25-25.87-1.7m-0.2um', 'G3.UW.NS-UW35-35.96-1.7m-0.2um', 'G3.UW.NS-UW32-32.3-1.7m-3um', 'G3.UW.NS-UW31-31.43-2.7m-3um', 'G3.UW.NS-UW40-40.09-2.7m-0.2um', 'G3.UW.NS-UW32-32.93-3.7m-3um', 'G3.UW.NS-UW25-25.87-1.7m-3um']\n",
    "\n",
    "lats = []\n",
    "infos = []\n",
    "for s in samples:\n",
    "    assm, sam, lat, depth, size = s.split('-')\n",
    "    lats.append(lat)\n",
    "    infos.append(f\"{lat}-{depth}-{size}\")\n",
    "\n",
    "infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxa = ['2864', '2696291', '35677', '49546', '28211', '3041', '135623', '1735725', '35127', '226']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K00264', 'K00265', 'K00284', 'K01673', 'K00266', 'K00615', 'K01624', 'K04759', 'K24034', 'K02364']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['G3.UW.NS-UW40-40.88-1.7m-3um', 'G3.UW.NS-UW40-40.88-1.7m-0.2um', 'G3.UW.NS-UW38-38.97-1.7m-3um', 'G3.UW.NS-UW29-29.46-1.7m-3um', 'G3.UW.NS-UW38-38.97-1.7m-0.2um', 'G3.UW.NS-UW35-35.96-1.7m-3um', 'G3.UW.NS-UW40-40.09-2.7m-3um', 'G3.UW.NS-UW35-35.96-1.7m-0.2um', 'G3.UW.NS-UW32-32.3-1.7m-3um', 'G3.UW.NS-UW25-25.87-1.7m-3um']\n",
    "\n",
    "lats = []\n",
    "infos = []\n",
    "for s in samples:\n",
    "    assm, sam, lat, depth, size = s.split('-')\n",
    "    lats.append(lat)\n",
    "    infos.append(f\"{lat}-{depth}-{size}\")\n",
    "\n",
    "infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taxa clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa = ['226', '2864', '3041', '28211', '31989', '35127', '35677', '49546',\n",
    "       '135623', '304208', '487796', '1735725', '2696291', '2854170']\n",
    "\n",
    "dict_tax_name = ncbi.get_taxid_translator(taxa)\n",
    "dtn = {}\n",
    "for t in taxa:\n",
    "    print(t,dict_tax_name[int(t)])\n",
    "    dtn[t] = dict_tax_name[int(t)]\n",
    "dtn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO clusters 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K07214', 'K10850', 'K04783', 'K00372', 'K23723', 'K16087', 'K04564',\n",
    "       'K00855', 'K02217', 'K02705']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO clusters 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K19611', 'K06503', 'K00265', 'K16090', 'K01851', 'K08906', 'K11707',\n",
    "       'K11709', 'K11710', 'K11951']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO clusters 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K01595', 'K00134', 'K01803', 'K01624', 'K16088', 'K00927', 'K00615',\n",
    "       'K04565', 'K04782', 'K11951']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO clusters 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K00264', 'K01595', 'K16087', 'K02638', 'K03699', 'K00175', 'K00265',\n",
    "       'K00179', 'K01601', 'K07684']\n",
    "\n",
    "for k in kos:\n",
    "    print(dict_ko_name[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample cluster 7 and 17 and 2 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K00265', 'K00368', 'K00615', 'K00855', 'K01012', 'K01601', 'K01602',\n",
    "       'K01624', 'K01672', 'K01673', 'K02364', 'K02639', 'K02689', 'K02695',\n",
    "       'K02699', 'K02703', 'K02704', 'K02705', 'K02706', 'K02708', 'K02711',\n",
    "       'K02717', 'K02718', 'K02721', 'K02722', 'K02724', 'K03320', 'K03542',\n",
    "       'K03594', 'K03839', 'K03841', 'K04564', 'K04565', 'K04755', 'K04759',\n",
    "       'K04784', 'K04787', 'K05374', 'K05524', 'K07214', 'K08940', 'K10850',\n",
    "       'K11645', 'K12237', 'K13859', 'K13860', 'K16087', 'K21567', 'K22336',\n",
    "       'K22552', 'K23723', 'K24110',\n",
    "       \n",
    "       'K00264', 'K00265', 'K00266', 'K00284', 'K00362', 'K00522', 'K00532',\n",
    "       'K00855', 'K01601', 'K01602', 'K02011', 'K02574', 'K02697', 'K02699',\n",
    "       'K02706', 'K02714', 'K02716', 'K02722', 'K03320', 'K03594', 'K03841',\n",
    "       'K04565', 'K04641', 'K04784', 'K04786', 'K06441', 'K06503', 'K08906',\n",
    "       'K11959', 'K13575', 'K14578', 'K15579', 'K16087', 'K19611', 'K19791',\n",
    "       'K21949', 'K22336', 'K22338', 'K22339', 'K23184', 'K23910', 'K25286',\n",
    "\n",
    "       'K02012', 'K02689', 'K02690', 'K02711', 'K02717', 'K02724',\n",
    "\n",
    "       'K00265', 'K00372', 'K01595', 'K02704', 'K02716', 'K02719', 'K02720',\n",
    "       'K03839', 'K04564', 'K04783', 'K05710', 'K07214', 'K14718', 'K23725',\n",
    "       'K24245'\n",
    "]\n",
    "dkn = {}\n",
    "for k in kos:\n",
    "    dkn[k] = dict_ko_name[k]\n",
    "dkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taxon cluster 1 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = [\n",
    "    'K00265', 'K01012', 'K01595', 'K01672', 'K01726', 'K02217', 'K02255',\n",
    "    'K02364', 'K02638', 'K02639', 'K03320', 'K04564', 'K04641', 'K04783',\n",
    "    'K04784', 'K05524', 'K07214', 'K12237', 'K16087', 'K19611', 'K22336',\n",
    "    'K22552', 'K23910', 'K25224',\n",
    "\n",
    "    'K03320'\n",
    "]\n",
    "dkn = {}\n",
    "for k in kos:\n",
    "    dkn[k] = dict_ko_name[k]\n",
    "dkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batch minimum tree trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../repo-armbrust-metat-search/functions')\n",
    "from cl_tree_trim_02 import TreeTrim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a test table with only two batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tidy_merge = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-tidy_all.csv'\n",
    "with open(fn_tidy_merge, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_meta = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-metadata.csv'\n",
    "metadata = pd.read_csv(fn_meta)\n",
    "metadata[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = ['D1PA','G1PA']\n",
    "fn_tidy_merge_sub = f\"/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-tidy_merge_{merges[0]}_{merges[1]}.csv\"\n",
    "out_dir = os.path.split(fn_tidy_merge_sub)[0]\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    print(f\"Made dir: {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dict sample batch\n",
    "dict_sample_batch = dict(zip(\n",
    "    metadata['fn_sample_counts'],\n",
    "    metadata['assembly']\n",
    "))\n",
    "merges = set(merges)  # faster \"in\"\n",
    "# count rows written\n",
    "i = 0\n",
    "# open read and write\n",
    "with open(fn_tidy_merge, 'r') as fr, open(fn_tidy_merge_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        contig, sample, ko, tax, estcounts = row.split(\",\")\n",
    "        batch = dict_sample_batch[sample]\n",
    "        if batch in merges:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim tree with subset merge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = TreeTrim(fn_tidy_merge_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.trim_tree(\n",
    "    'nkos_in_gt_minbatches',\n",
    "    thresh=30,\n",
    "    dict_sample_batch=dict_sample_batch,\n",
    "    minsamples=3,\n",
    "    minbatches=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.treetrim.to_str(props=['sci_name','name'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add info to trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tree.treetrim.traverse():\n",
    "    tid = n.name\n",
    "    nkos = 0\n",
    "    for ko, d in tree.dict_taxtrim_ko_sam_estcounts[tid].items():\n",
    "        dbs = defaultdict(int)\n",
    "        for sam, estcounts in d.items():\n",
    "            batch = dict_sample_batch[sam]\n",
    "            dbs[batch] += bool(estcounts)\n",
    "        minb = True\n",
    "        for nsam in dbs.values():\n",
    "            if nsam < 3:\n",
    "                minb = False\n",
    "        if minb:\n",
    "            nkos += 1\n",
    "    n.add_props(\n",
    "        nkos=nkos\n",
    "    )\n",
    "print(tree.treetrim.to_str(props=['sci_name','name','nkos'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_name['K08906']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = [\n",
    "    'K07214', 'K02364', 'K02639'\n",
    "]\n",
    "\n",
    "for ko in kos:\n",
    "    print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize barnacle fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_table_summary = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/barnacle/table_summary_barnacle_fitting.csv'\n",
    "df_summary = pd.read_csv(fn_table_summary)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove failed rows and convert all to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfailed = df_summary['Column 1'] != 'FAILED'\n",
    "df_summary_trim = df_summary[notfailed]\n",
    "df_summary_trim = df_summary_trim.drop('Column 1', axis=1)\n",
    "df_summary_trim = df_summary_trim.astype(str)\n",
    "for col in df_summary_trim.columns:\n",
    "    df_summary_trim[col] = df_summary_trim[col].str.replace(',','')\n",
    "df_summary_trim = df_summary_trim.astype(float)\n",
    "df_summary_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shp = len(df_summary_trim.columns)\n",
    "# arr_corr = np.zeros((shp,shp))\n",
    "# arr_pval = np.zeros((shp,shp))\n",
    "# for i, coli in enumerate(df_summary_trim.columns):\n",
    "#     for j, colj in enumerate(df_summary_trim.columns):\n",
    "#         if coli < colj:\n",
    "#             ci = df_summary_trim[coli]\n",
    "#             cj = df_summary_trim[colj]\n",
    "#             corr = stats.spearmanr(ci, cj)\n",
    "#             arr_corr[i,j] = corr.statistic\n",
    "#             arr_pval[i,j] = corr.pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df_summary_trim.corr()\n",
    "corr_df = corr_df.replace({np.nan: 0})\n",
    "# Precalculate linkage to extract clusters later\n",
    "link = hierarchy.linkage(distance.pdist(np.asarray(corr_df)))\n",
    "# make clustered heatmap\n",
    "# using precalculated linkage\n",
    "g = sns.clustermap(\n",
    "    corr_df.fillna(0), \n",
    "    row_linkage=link, col_linkage=link,\n",
    "    mask=corr_df.isna(), \n",
    "    cmap='PuOr_r', vmin=-1, vmax=1, \n",
    "    cbar_kws={'shrink':0.5, 'label':'Pearson\\nCorrelation'}, \n",
    "    xticklabels=True, yticklabels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot filled cells vs rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_trim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'rank'\n",
    "y = 'number of filled cells (tax-ko-sam_rep with estcounts > 0)'\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(\n",
    "    df_summary_trim[x],\n",
    "    df_summary_trim[y]\n",
    ")\n",
    "ax.set_xlabel(x)\n",
    "ax.set_ylabel(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SSE vs taxon-kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'number of taxa-kos (with estcounts > 0)'\n",
    "y = 'SSE'\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(\n",
    "    df_summary_trim[x],\n",
    "    df_summary_trim[y]\n",
    ")\n",
    "ax.set_xlabel(x)\n",
    "ax.set_ylabel(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total cells vs rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'rank'\n",
    "y = 'Number of cells'\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(\n",
    "    df_summary_trim[x],\n",
    "    df_summary_trim[y]\n",
    ")\n",
    "ax.set_xlabel(x)\n",
    "ax.set_ylabel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{5084*3*178:,d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{355*65*531:,d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "355*65*531/500000*80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "355*65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation between enterobactin esterase and pelagomonas abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tidy_merge_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tidy_tables/merge_all/iron_KOs.txt-barnacle_tensor_tidy-subset_taxa_03-subset_batches_01.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = 'K07214'  # enterobactin esterase\n",
    "tid = '35677'  # Pelagomonas calceolata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sam_koestcounts = defaultdict(float)\n",
    "dict_sam_tidestcounts = defaultdict(float)\n",
    "with open(fn_tidy_merge_sub, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['taxon_trim'] == tid:\n",
    "            sam = row['assm_sample']\n",
    "            estcounts = float(row['estcounts'])\n",
    "            ko_ = row['KO']\n",
    "            dict_sam_tidestcounts[sam] += estcounts\n",
    "            if ko_ == ko:\n",
    "                dict_sam_koestcounts[sam] += estcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get df of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "sams = set(dict_sam_koestcounts.keys()).union(set(dict_sam_tidestcounts.keys()))\n",
    "koestcounts = []\n",
    "tidestcounts = []\n",
    "for sam in sams:\n",
    "    koestcounts.append(dict_sam_koestcounts.get(sam, 0))\n",
    "    tidestcounts.append(dict_sam_tidestcounts.get(sam, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(tidestcounts, koestcounts)\n",
    "ax.set_ylabel(f'{ko} counts')\n",
    "ax.set_xlabel(f'{tid} counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(tidestcounts, koestcounts)\n",
    "ax.set_ylabel(f'Pelagomonas calceolata\\nEnterobactin esterase counts')\n",
    "ax.set_xlabel(f'Pelagomonas calceolata counts')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.axis('equal')\n",
    "ax.plot([10,20,40,80,160,320,500],[10,20,40,80,160,320,500],'k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(tidestcounts, koestcounts)\n",
    "ax.set_ylabel(f'Pelagomonas calceolata\\nEnterobactin esterase counts')\n",
    "ax.set_xlabel(f'Pelagomonas calceolata counts')\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.plot([10,20,40,80,160,320,500],[10,20,40,80,160,320,500],'k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "any([x == 0 for x in koestcounts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fraction of ko vs pelag total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(tidestcounts, np.array(koestcounts)/ np.array(tidestcounts))\n",
    "ax.set_ylabel(f'Pelagomonas calceolata\\nEnterobactin esterase counts')\n",
    "ax.set_xlabel(f'Pelagomonas calceolata counts')\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "# ax.plot([10,20,40,80,160,320,500],[10,20,40,80,160,320,500],'k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict for all kos in tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_sam_estcounts = defaultdict(lambda: defaultdict(float))\n",
    "with open(fn_tidy_merge_sub, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['taxon_trim'] == tid:\n",
    "            sam = row['assm_sample']\n",
    "            estcounts = float(row['estcounts'])\n",
    "            ko = row['KO']\n",
    "            dict_ko_sam_estcounts[ko][sam] += estcounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which ko is in most samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = []\n",
    "nsams = []\n",
    "for ko, dict_sam_estcounts in dict_ko_sam_estcounts.items():\n",
    "    kos.append(ko)\n",
    "    ns = 0\n",
    "    for sam, estcounts in dict_sam_estcounts.items():\n",
    "        if estcounts > 0:\n",
    "            ns += 1\n",
    "    nsams.append(ns)\n",
    "kos = [x for _, x in sorted(zip(nsams, kos))]\n",
    "nsams = sorted(nsams)\n",
    "dict_ko_nsams = dict(zip(kos, nsams))\n",
    "pd.DataFrame({\"kos\":kos, \"nsams\":nsams})[-20:], dict_ko_nsams['K07214']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_name['K02575']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot target vs common ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K02575', 'K07214']\n",
    "vals = []\n",
    "for ko in kos:\n",
    "    d = dict_ko_sam_estcounts[ko]\n",
    "    v = []\n",
    "    for sam in sams:\n",
    "        v.append(d[sam])\n",
    "    vals.append(v)\n",
    "\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(vals[0], vals[1])\n",
    "ax.set_xlabel(f\"{dict_ko_name[kos[0]]}\\nestcounts\")\n",
    "ax.set_ylabel(f\"{dict_ko_name[kos[1]]}\\nestcounts\")\n",
    "ax.set_xscale('log')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K02364', 'K07214']\n",
    "vals = []\n",
    "for ko in kos:\n",
    "    d = dict_ko_sam_estcounts[ko]\n",
    "    v = []\n",
    "    for sam in sams:\n",
    "        v.append(d[sam])\n",
    "    vals.append(v)\n",
    "\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(vals[0], vals[1])\n",
    "ax.set_xlabel(f\"{dict_ko_name[kos[0]]}\\nestcounts\")\n",
    "ax.set_ylabel(f\"{dict_ko_name[kos[1]]}\\nestcounts\")\n",
    "ax.set_xscale('log')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K16267', 'K07214']\n",
    "vals = []\n",
    "for ko in kos:\n",
    "    d = dict_ko_sam_estcounts[ko]\n",
    "    v = []\n",
    "    for sam in sams:\n",
    "        v.append(d[sam])\n",
    "    vals.append(v)\n",
    "\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(vals[0], vals[1])\n",
    "ax.set_xlabel(f\"{dict_ko_name[kos[0]]}\\nestcounts\")\n",
    "ax.set_ylabel(f\"{dict_ko_name[kos[1]]}\\nestcounts\")\n",
    "ax.set_xscale('log')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which samples have the most esterase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_ko = np.array(koestcounts)/ np.array(tidestcounts)\n",
    "sams_fracsort = [x for _, x in sorted(zip(frac_ko, sams))]\n",
    "frac_ko_sort = sorted(frac_ko)\n",
    "pd.DataFrame({\"sams_fracsort\":sams_fracsort, \"frac_ko\":frac_ko_sort})[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'G3PA-UW32#3-7-3.0'\n",
    "dke = {}\n",
    "for ko, d in dict_ko_sam_estcounts.items():\n",
    "    ec = d[s]\n",
    "    if ec > 0:\n",
    "        dke[dict_ko_name[ko]] = ec\n",
    "dke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'G3PA-UW32-7-3.0'\n",
    "dke = {}\n",
    "for ko, d in dict_ko_sam_estcounts.items():\n",
    "    ec = d[s]\n",
    "    if ec > 0:\n",
    "        dke[dict_ko_name[ko]] = ec\n",
    "dke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(sn_type):\n",
    "    meta_fn = input_table.loc[\n",
    "        input_table['sn_type_parse_kallisto'] == sn_type, \n",
    "        'fn_sample_metadata'\n",
    "    ].values[0]\n",
    "    return pd.read_csv(meta_fn)\n",
    "\n",
    "def get_size_lat_depth_rep_timep(meta_sample, rnd_lat, skip=[]):\n",
    "    vals = []\n",
    "    if not 'size' in skip:\n",
    "        size = str(float(meta_sample['Filter'].values[0]))\n",
    "        size += 'um'\n",
    "        vals.append(size)\n",
    "    if not 'lat' in skip:\n",
    "        lat = str(round(float(meta_sample['Latitude'].values[0]), rnd_lat))\n",
    "        lat += 'deg'\n",
    "        vals.append(lat)\n",
    "    if not 'depth' in skip:\n",
    "        depth = str(float(meta_sample['Depth'].values[0]))\n",
    "        depth += 'm'\n",
    "        vals.append(depth)\n",
    "    if not 'rep' in skip:\n",
    "        rep = meta_sample['Replicate'].values[0]\n",
    "        vals.append(rep)\n",
    "    if not 'timep' in skip:\n",
    "        timep = meta_sample['Datetime'].values[0]\n",
    "        timep = re.sub('/','_', timep)\n",
    "        timep = re.sub(r'\\s','-', timep)\n",
    "        vals.append(timep)\n",
    "    return vals\n",
    "\n",
    "def parse_fn_kallisto_sn(fn='', sn_type='', get_columns=False, rnd_lat=2):\n",
    "    if not get_columns:\n",
    "        ass, sample, lat, ammend, timep, depth, size, rep = [''] * 8\n",
    "        if sn_type == 'G1NS':\n",
    "            splt = fn.split('.')\n",
    "            ass, sm_sz, rp = splt[:3]\n",
    "            sample, sz = sm_sz.split('_',1)\n",
    "            # size = str(float(re.sub('_','.',sz)))\n",
    "            alias2 = sm_sz + rp\n",
    "            meta = get_meta(sn_type)\n",
    "            meta_sample = meta.loc[meta['Alias2'] == alias2, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "        elif sn_type == 'G2NS':\n",
    "            ass, sample, dp, sz, rp, _ = fn.split('.')\n",
    "            meta = get_meta(sn_type)\n",
    "            alias2 = f'{sample}.{dp}.{sz}.{rp}'\n",
    "            meta_sample = meta.loc[meta['Alias2'] == alias2, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "        elif sn_type == 'G3NS':\n",
    "            meta = get_meta(sn_type)\n",
    "            sid = os.path.splitext(fn)[0]\n",
    "            meta_sample = meta.loc[meta['SampleID'] == sid, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "            ass = re.match(r'.+NS', fn)[0]\n",
    "            sample = re.search(r'UW\\d+_\\d', fn)[0]\n",
    "        elif sn_type == 'G5':\n",
    "            ass, sample, ammend, timep, rep, _ = fn.split('.')\n",
    "        elif sn_type == 'D1':\n",
    "            ass, sm_rep_tp, _, _ = fn.split('.')\n",
    "            sample, rep, timep = sm_rep_tp.split('_')\n",
    "        elif sn_type == 'G1PA':\n",
    "            meta = get_meta(sn_type)\n",
    "            ass, fn_ = fn.split('.', 1)\n",
    "            sid = re.match(r'.+(?=\\.abundance)', fn_)[0]\n",
    "            sid = re.sub(r'\\.','_',sid)\n",
    "            meta_sample = meta.loc[meta['SampleID'] == sid, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "            sample, _ = fn_.split('_', 1)\n",
    "        elif sn_type == 'G2PA':\n",
    "            _, ass, sample, dp, sz, rp, _, _ = fn.split('.')\n",
    "            meta = get_meta(sn_type)\n",
    "            sid = f\"{sample}.{dp}.{sz}.{rp}\"\n",
    "            meta_sample = meta.loc[meta['SampleID'] == sid, :]\n",
    "            size, lat, rep = get_size_lat_depth_rep_timep(\n",
    "                meta_sample, \n",
    "                rnd_lat, \n",
    "                skip=['depth','timep']\n",
    "            )\n",
    "            depth = str(float(dp[:-1])) + 'm'\n",
    "            # size = re.sub('_','.',sz)\n",
    "        elif sn_type == 'G3PA.UW':\n",
    "            meta = get_meta(sn_type)\n",
    "            ass, sample_ = fn.split('.')[:2]\n",
    "            meta_sample = meta.loc[meta['Alias2'] == sample_, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "            sample_list = str(meta_sample['Alias1'].values[0]).split(' ')\n",
    "            sample = sample_list[0]\n",
    "            if '#' in sample_list[1]:\n",
    "                sample += sample_list[1]\n",
    "        elif sn_type == 'G3PA.diel':\n",
    "            ass1, ass2, sample, rp, _, _, _, _ = fn.split('.')\n",
    "            ass = f'{ass1}.{ass2}'\n",
    "            meta = get_meta(sn_type)\n",
    "            sid = f\"{ass}.{sample}.{rp}\"\n",
    "            meta_sample = meta.loc[meta['SampleID'] == sid, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "\n",
    "        elif sn_type == 'G3PA.PM':\n",
    "            ass = sn_type\n",
    "            sample = re.search(r'UW\\d+_\\d', fn)[0]\n",
    "            meta = get_meta(sn_type)\n",
    "            sid = re.match(r'.+(?=\\.unstranded)', fn)[0]\n",
    "            print(sid)\n",
    "            meta_sample = meta.loc[meta['SampleID'] == sid, :]\n",
    "            size, lat, depth, rep, timep = get_size_lat_depth_rep_timep(meta_sample, rnd_lat)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"\"\"\n",
    "                Sample name parse type {sn_type} not configured or not provided \n",
    "                (sn_type_parse_kallisto column in file table)\n",
    "                \"\"\"\n",
    "            )\n",
    "        return [ass, sample, lat, ammend, timep, depth, size, rep]\n",
    "    else:\n",
    "        return ['assembly', 'sample', 'latitude','ammendment', 'timepoint', 'depth', 'size', 'rep']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_table_fn = 'file_table.240210.kofam_filt.csv'\n",
    "input_table = pd.read_csv(input_table_fn, keep_default_na=False)\n",
    "# fn = 'G3.UW.NS.UW40_2.7m.0_2um.A.tsv'\n",
    "# fn = 'G3.UW.NS.UW40_1.7m.3um.B.tsv'\n",
    "# sn_type = 'G3NS'\n",
    "# fn = 'G1NS.S13C1_3um.B.tsv'\n",
    "# sn_type = 'G1NS'\n",
    "# fn = 'G2NS.S18C1.15m.3um.B.tsv'\n",
    "# sn_type = 'G2NS'\n",
    "fn = 'G1PA.S10_0.2umA.abundance.tsv'\n",
    "sn_type = 'G1PA'\n",
    "# fn = 'G2PA.G2PA.S18C1.15m.3um.C.abundance.tsv'\n",
    "# sn_type = 'G2PA'\n",
    "# fn = 'G3PA.UW9.unstranded.abundance.tsv'\n",
    "# sn_type = 'G3PA.UW'\n",
    "# fn = 'G3PA.diel.S4C8.C.unstranded.abundance.tsv.gz'\n",
    "# sn_type = 'G3PA.diel'\n",
    "# fn = 'G3.UW.PA.UW42_1.7m_PM.3um.C.unstranded.abundance.tsv.gz'\n",
    "# sn_type = 'G3PA.PM'\n",
    "dict(zip(parse_fn_kallisto_sn(get_columns=True), parse_fn_kallisto_sn(fn, sn_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = '4/16/19 13:39'\n",
    "datetime = re.sub('/','_', datetime)\n",
    "datetime = re.sub(r'\\s','-', datetime)\n",
    "datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset tree_trim_thresh_60_minsamples_20_minbatches_4 to only bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4-sub_taxa_bact.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species, taxid, nkos\n",
    "nodes_sub_bact = [\n",
    "    \"Bacteria,2,334\",\n",
    "    \"Bacteroidota,976,277\",\n",
    "    \"Pseudomonadota,1224,282\",\n",
    "    \"Alphaproteobacteria,28211,270\",\n",
    "    \"Gammaproteobacteria,1236,316\"\n",
    "]\n",
    "\n",
    "taxa_sub = []\n",
    "# for t in nodes_sub_01:\n",
    "for t in nodes_sub_bact:\n",
    "    _, tid, _ = t.split(',')\n",
    "    taxa_sub.append(tid)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator(taxa_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "shps = {\"KO\": 254, \"taxon_trim\": 5, \"sample_replicate_id\": 474}\n",
    "f\"{np.prod(list(shps.values())):,d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset tree_trim_thresh_60_minsamples_20_minbatches_4 to only Ochrophyta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4-sub_taxa_ochrophyta.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Species, taxid, nkos\n",
    "# nodes_sub_bact = [\n",
    "#     \"Bacteria,2,334\",\n",
    "#     \"Bacteroidota,976,277\",\n",
    "#     \"Pseudomonadota,1224,282\",\n",
    "#     \"Alphaproteobacteria,28211,270\",\n",
    "#     \"Gammaproteobacteria,1236,316\"\n",
    "# ]\n",
    "\n",
    "# taxa_sub = []\n",
    "# # for t in nodes_sub_01:\n",
    "# for t in nodes_sub_bact:\n",
    "#     _, tid, _ = t.split(',')\n",
    "#     taxa_sub.append(tid)\n",
    "\n",
    "tax_groupby = '2696291'  # Ochrophyta\n",
    "taxa_sub = [n.name for n in tree[tax_groupby].descendants()]\n",
    "taxa_sub.append(tax_groupby)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator(taxa_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "shps = {\"KO\": 177, \"taxon_trim\": 5, \"sample_replicate_id\": 531}\n",
    "f\"{np.prod(list(shps.values())):,d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset tree_trim_thresh_60_minsamples_20_minbatches_4 to only Dinophyceae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4-sub_taxa_dinophyceae.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Species, taxid, nkos\n",
    "# nodes_sub_bact = [\n",
    "#     \"Bacteria,2,334\",\n",
    "#     \"Bacteroidota,976,277\",\n",
    "#     \"Pseudomonadota,1224,282\",\n",
    "#     \"Alphaproteobacteria,28211,270\",\n",
    "#     \"Gammaproteobacteria,1236,316\"\n",
    "# ]\n",
    "\n",
    "# taxa_sub = []\n",
    "# # for t in nodes_sub_01:\n",
    "# for t in nodes_sub_bact:\n",
    "#     _, tid, _ = t.split(',')\n",
    "#     taxa_sub.append(tid)\n",
    "\n",
    "tax_groupby = '2864'  # Dinophyceae\n",
    "taxa_sub = [n.name for n in tree[tax_groupby].descendants()]\n",
    "taxa_sub.append(tax_groupby)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "shps = {\"KO\": 243, \"taxon_trim\": 6, \"sample_replicate_id\": 531}\n",
    "f\"{np.prod(list(shps.values())):,d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset tree_trim_thresh_60_minsamples_20_minbatches_4 to only Viridiplantae, Prmnesiophyceae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4-sub_taxa_viridiplantae_prymnesiophyceae.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Species, taxid, nkos\n",
    "# nodes_sub_bact = [\n",
    "#     \"Bacteria,2,334\",\n",
    "#     \"Bacteroidota,976,277\",\n",
    "#     \"Pseudomonadota,1224,282\",\n",
    "#     \"Alphaproteobacteria,28211,270\",\n",
    "#     \"Gammaproteobacteria,1236,316\"\n",
    "# ]\n",
    "\n",
    "# taxa_sub = []\n",
    "# # for t in nodes_sub_01:\n",
    "# for t in nodes_sub_bact:\n",
    "#     _, tid, _ = t.split(',')\n",
    "#     taxa_sub.append(tid)\n",
    "\n",
    "tax_groupby = ['33090','2608131']  # Viridiplantae, Prymnesiophyceae\n",
    "taxa_sub = []\n",
    "for t in tax_groupby:\n",
    "    taxa_sub += [n.name for n in tree[t].descendants()]\n",
    "    taxa_sub.append(t)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator(taxa_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "shps = {\"KO\": 203, \"taxon_trim\": 6, \"sample_replicate_id\": 531}\n",
    "f\"{np.prod(list(shps.values())):,d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset tree_trim_thresh_60_minsamples_20_minbatches_4 to only Opisthokonta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4-sub_taxa_viridiplantae_opisthokonta.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Species, taxid, nkos\n",
    "# nodes_sub_bact = [\n",
    "#     \"Bacteria,2,334\",\n",
    "#     \"Bacteroidota,976,277\",\n",
    "#     \"Pseudomonadota,1224,282\",\n",
    "#     \"Alphaproteobacteria,28211,270\",\n",
    "#     \"Gammaproteobacteria,1236,316\"\n",
    "# ]\n",
    "\n",
    "# taxa_sub = []\n",
    "# # for t in nodes_sub_01:\n",
    "# for t in nodes_sub_bact:\n",
    "#     _, tid, _ = t.split(',')\n",
    "#     taxa_sub.append(tid)\n",
    "\n",
    "tax_groupby = ['33154']  # Opisthokonta\n",
    "taxa_sub = []\n",
    "for t in tax_groupby:\n",
    "    taxa_sub += [n.name for n in tree[t].descendants()]\n",
    "    taxa_sub.append(t)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator(taxa_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "shps = {\"KO\": 227, \"taxon_trim\": 4, \"sample_replicate_id\": 531}\n",
    "f\"{np.prod(list(shps.values())):,d}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset tree_trim_thresh_60_minsamples_20_minbatches_4 to only high level groups and opisthokonta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tensor filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4.csv'\n",
    "os.path.exists(fn_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_tensor, 'r') as f:\n",
    "    print(next(f))\n",
    "    print(next(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tensor_sub = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/tree_trim/merge_all/iron_KOs.txt-barnacle_tensor_tidy-tree_trim_thresh_60_minsamples_20_minbatches_4-sub_taxa_highlevel_opisthokonta.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxa to subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species, taxid, nkos\n",
    "nodes_sub_high = [\n",
    "    \"cellular organisms,131567,351\",\n",
    "    \"Eukaryota,2759,342\",\n",
    "    \"Sar,2698737,287\",\n",
    "]\n",
    "\n",
    "taxa_sub = []\n",
    "# for t in nodes_sub_01:\n",
    "for t in nodes_sub_high:\n",
    "    _, tid, _ = t.split(',')\n",
    "    taxa_sub.append(tid)\n",
    "\n",
    "tax_groupby = ['33154']  # Opisthokonta\n",
    "for t in tax_groupby:\n",
    "    taxa_sub += [n.name for n in tree[t].descendants()]\n",
    "    taxa_sub.append(t)\n",
    "\n",
    "taxa_sub = set(taxa_sub)\n",
    "taxa_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator(taxa_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write rows to tidytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(fn_tensor, 'r') as fr, open(fn_tensor_sub, 'w') as fw:\n",
    "    row = next(fr)\n",
    "    fw.write(row)\n",
    "    for row in fr:\n",
    "        sample, ko, tax, estcounts, rep = row.split(\",\")\n",
    "        if tax in taxa_sub:\n",
    "            i += 1\n",
    "            fw.write(row)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shps = {\"KO\": 227, \"taxon_trim\": 4, \"sample_replicate_id\": 531}\n",
    "f\"{np.prod(list(shps.values())):,d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28164865-27841030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r'_\\d+$','abcd_i1')[0]  # Remove \"_{digit}\" aa reading frame from the contig name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r'_\\d+$','abcd_i1')[0]  # Remove \"_{digit}\" aa reading frame from the contig name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata['sample'] == 'S02C1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
