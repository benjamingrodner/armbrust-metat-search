{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect taxonomy of marferret and marmicrodb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import umap\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from collections import * \n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "from ete4 import NCBITaxa, Tree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../repo-armbrust-metat-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.fn_metat_files as fnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/scratch/bgrodner/iron_ko_contigs'\n",
    "os.chdir(workdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_plot(\n",
    "    xlabel=\"\", ylabel=\"\", ft=12, dims=(5, 3), col=\"k\", lw=1, pad=0, tr_spines=True\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(dims[0], dims[1]), tight_layout={\"pad\": pad})\n",
    "    for i in ax.spines:\n",
    "        ax.spines[i].set_linewidth(lw)\n",
    "    if not tr_spines:\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "    else:\n",
    "        ax.spines[\"top\"].set_color(col)\n",
    "        ax.spines[\"right\"].set_color(col)\n",
    "    ax.spines[\"bottom\"].set_color(col)\n",
    "    ax.spines[\"left\"].set_color(col)\n",
    "    ax.tick_params(direction=\"in\", labelsize=ft, color=col, labelcolor=col)\n",
    "    ax.set_xlabel(xlabel, fontsize=ft, color=col)\n",
    "    ax.set_ylabel(ylabel, fontsize=ft, color=col)\n",
    "    ax.patch.set_alpha(0)\n",
    "    return (fig, ax)\n",
    "\n",
    "def plot_umap(\n",
    "    embedding,\n",
    "    figsize=(10, 10),\n",
    "    markersize=10,\n",
    "    alpha=0.5,\n",
    "    colors=\"k\",\n",
    "    xticks=[],\n",
    "    yticks=[],\n",
    "    markerstyle='o',\n",
    "    cmap_name='tab20',\n",
    "    cl_lab=False\n",
    "):\n",
    "    fig, ax = general_plot(dims=figsize)\n",
    "    if isinstance(markerstyle, str):\n",
    "        ax.scatter(\n",
    "            embedding[:, 0],\n",
    "            embedding[:, 1],\n",
    "            s=markersize,\n",
    "            alpha=alpha,\n",
    "            c=colors,\n",
    "            edgecolors=\"none\",\n",
    "            marker=markerstyle,\n",
    "            cmap=cmap_name\n",
    "        )\n",
    "    else:\n",
    "        for e0, e1, c, m in zip(\n",
    "            embedding[:, 0], \n",
    "            embedding[:, 1],\n",
    "            colors,\n",
    "            markerstyle \n",
    "        ):\n",
    "            ax.scatter(\n",
    "                e0,\n",
    "                e1,\n",
    "                s=markersize,\n",
    "                alpha=alpha,\n",
    "                c=c,\n",
    "                edgecolors=\"none\",\n",
    "                marker=m\n",
    "            )\n",
    "    ax.set_aspect(\"equal\")\n",
    "    if len(xticks) > 0:\n",
    "        ax.set_xticks(xticks)\n",
    "    if len(yticks) > 0:\n",
    "        ax.set_yticks(yticks)\n",
    "    ax.set_xlabel(\"UMAP 1\")\n",
    "    ax.set_ylabel(\"UMAP 2\")\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get KO dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_fn = \"ko00001.json\"\n",
    "database = list()\n",
    "for _, v in pd.read_json(ko_fn).iterrows():\n",
    "    d = v[\"children\"]\n",
    "    cat_1 = d[\"name\"]\n",
    "    for child_1 in d[\"children\"]:\n",
    "        cat_2 = child_1[\"name\"] # Module?\n",
    "        for child_2 in child_1[\"children\"]:\n",
    "            cat_3 = child_2[\"name\"]\n",
    "            if \"children\" in child_2:\n",
    "                for child_3 in child_2[\"children\"]:\n",
    "                    cat_4 = child_3[\"name\"]\n",
    "                    fields = [cat_1, cat_2, cat_3, cat_4]\n",
    "                    database.append(fields)\n",
    "df_kegg = pd.DataFrame(database, columns=[\"Level_A\", \"Level_B\", \"Level_C\", \"Level_D\"])\n",
    "df_kegg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = df_kegg['Level_D'].values\n",
    "ld[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_name = {}\n",
    "for name in ld:\n",
    "    ko = re.search(r\"^\\w+\",name)[0]\n",
    "    dict_ko_name[ko] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect marmicrodb table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_marmicro = '/scratch/bgrodner/iron_ko_contigs/MARMICRODB_catalog.tsv'\n",
    "\n",
    "# marmicro = pd.read_csv(fn_marmicro, on_bad_lines='warn')\n",
    "# marmicro.shape\n",
    "\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout skipped lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_skipped = '''\n",
    "    Skipping line 15696: expected 1 fields, saw 3\n",
    "    Skipping line 15712: expected 1 fields, saw 5\n",
    "    Skipping line 15713: expected 1 fields, saw 5\n",
    "    Skipping line 15714: expected 1 fields, saw 5\n",
    "    Skipping line 15715: expected 1 fields, saw 5\n",
    "    Skipping line 15716: expected 1 fields, saw 5\n",
    "    Skipping line 15717: expected 1 fields, saw 5\n",
    "    Skipping line 15718: expected 1 fields, saw 5\n",
    "    Skipping line 18585: expected 1 fields, saw 2\n",
    "    Skipping line 18587: expected 1 fields, saw 2\n",
    "    Skipping line 18605: expected 1 fields, saw 2\n",
    "    Skipping line 18642: expected 1 fields, saw 2\n",
    "    Skipping line 18646: expected 1 fields, saw 2\n",
    "    Skipping line 18657: expected 1 fields, saw 2\n",
    "    Skipping line 18658: expected 1 fields, saw 2\n",
    "    Skipping line 18660: expected 1 fields, saw 2\n",
    "    Skipping line 18661: expected 1 fields, saw 2\n",
    "    Skipping line 18664: expected 1 fields, saw 2\n",
    "    Skipping line 18677: expected 1 fields, saw 2\n",
    "    Skipping line 18701: expected 1 fields, saw 2\n",
    "    Skipping line 18712: expected 1 fields, saw 2\n",
    "    Skipping line 18713: expected 1 fields, saw 2\n",
    "    Skipping line 18732: expected 1 fields, saw 2\n",
    "    Skipping line 18741: expected 1 fields, saw 2\n",
    "    Skipping line 18742: expected 1 fields, saw 2\n",
    "    Skipping line 18743: expected 1 fields, saw 2\n",
    "    Skipping line 18744: expected 1 fields, saw 2\n",
    "    Skipping line 18760: expected 1 fields, saw 2\n",
    "'''\n",
    "set_skipped = re.findall(r'(?<=line\\s)\\d+',text_skipped)\n",
    "set_skipped = set([int(l) for l in set_skipped])\n",
    "set_skipped.add(15694)\n",
    "\n",
    "i = 0\n",
    "with open(fn_marmicro, 'r') as f:\n",
    "    _ = next(f)\n",
    "    for row in f:\n",
    "        if i in set_skipped:\n",
    "            print(i, len(row.split('\\t')))\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load with csv reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "with open(fn_marmicro, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        lens.append(len(row))\n",
    "\n",
    "set(lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_marmicro_col_row = {}\n",
    "with open(fn_marmicro, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader)\n",
    "    for h in header:\n",
    "        dict_marmicro_col_row[h] = []\n",
    "    for row in reader:\n",
    "        for c, v in zip(header, row):\n",
    "            dict_marmicro_col_row[c].append(v)\n",
    "\n",
    "marmicro = pd.DataFrame(dict_marmicro_col_row)\n",
    "marmicro.shape, marmicro[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of taxids not in NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "not ncbi.get_taxid_translator([12345647278763])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_missing =[]\n",
    "taxids = marmicro['taxid'].values\n",
    "for idx, t in enumerate(taxids):\n",
    "    try:\n",
    "        int(t)           \n",
    "    except:\n",
    "        tax_missing.append(idx)\n",
    "\n",
    "marmicro.iloc[tax_missing, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_missing =[]\n",
    "taxids = marmicro['taxid'].values\n",
    "for idx, t in enumerate(taxids):\n",
    "    try:\n",
    "        d = ncbi.get_taxid_translator([t])\n",
    "        if not d:\n",
    "            tax_missing.append(idx)\n",
    "    except:\n",
    "        tax_missing.append(idx)\n",
    "\n",
    "marmicro.iloc[tax_missing, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_missing =[]\n",
    "taxids = marmicro['MARMICRODBtaxid'].values\n",
    "for idx, t in enumerate(taxids):\n",
    "    try:\n",
    "        int(t)           \n",
    "    except:\n",
    "        tax_missing.append(idx)\n",
    "\n",
    "marmicro.iloc[tax_missing, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get taxids for the NA taxids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_na = marmicro.loc[marmicro['taxid'] == 'NA', 'full_name'].values\n",
    "names_na_fix = []\n",
    "for n in names_na:\n",
    "    if \"MIT\" in n:\n",
    "        n = re.sub('MIT', 'MIT ', n)\n",
    "    elif '150SLHB' in n:\n",
    "        n = 'Prochlorococcus sp. P1344'\n",
    "    elif '150SLHA' in n:\n",
    "        n = 'Prochlorococcus sp.P1363'    \n",
    "    elif '150NLHA' in n:\n",
    "        n = 'Prochlorococcus sp. P1361'\n",
    "    if '1418' in n:\n",
    "        n = 'Prochlorococcus sp.'\n",
    "    matches = [s in n for s in ['1013','1214','0918','0919',]]\n",
    "    if any(matches):\n",
    "        n = re.sub('coccus sp.', 'coccus marinus str.',n)\n",
    "\n",
    "    names_na_fix.append(n)\n",
    "names_na_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdbtaxid_na = marmicro.loc[marmicro['taxid'] == 'NA', 'MARMICRODBtaxid'].values\n",
    "mmdbtaxid_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = {\n",
    "    'MMDB taxid':[],\n",
    "    'NCBI taxid':[],\n",
    "    'MMDB name':[],\n",
    "    'NCBI name':[],\n",
    "}\n",
    "for t, n, nf in zip(mmdbtaxid_na, names_na, names_na_fix):\n",
    "    d = ncbi.get_name_translator([nf])\n",
    "    if d:\n",
    "        tf = d[nf][0]\n",
    "    else:\n",
    "        tf = ''\n",
    "        nf = ''\n",
    "    trans['MMDB taxid'].append(t)\n",
    "    trans['NCBI taxid'].append(tf)\n",
    "    trans['MMDB name'].append(n)\n",
    "    trans['NCBI name'].append(nf)\n",
    "trans_df = pd.DataFrame(trans)\n",
    "trans_df.to_csv('/scratch/bgrodner/Resources/MARMICRODB_prochlorococcus_taxids.csv')\n",
    "trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "marmicro_mismatch = marmicro[marmicro['MARMICRODBtaxid'] != marmicro['taxid']]\n",
    "marmicro_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "marmicro_mismatch[marmicro_mismatch['sequence_type'] == 'isolate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_isolate = marmicro_mismatch['sequence_type'] == 'isolate'\n",
    "bool_pro = marmicro_mismatch['taxgroup'] == 'prochlorococcus'\n",
    "marmicro_mismatch[bool_isolate & bool_pro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_test = marmicro['genome'] == 'MMP03755233'\n",
    "marmicro[bool_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "28164865-27841030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_test = marmicro['MARMICRODBtaxid'] == '1577725'\n",
    "marmicro[bool_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare mmmdb ncbi mapping to actual taxid ncbi mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in marmicro_mismatch.iterrows():\n",
    "    t = row.taxid  \n",
    "    n = ncbi.get_taxid_translator([t])[int(t)] if t != 'NA' else 'NA'\n",
    "    mt = row.MARMICRODBtaxid\n",
    "    mn = ncbi.get_taxid_translator([mt])\n",
    "    mn = mn[int(mt)] if mn else 0\n",
    "    print(n, '\\t', mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare written lineage to ncbi lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_test = marmicro['MARMICRODBtaxid'] == '2182669'\n",
    "marmicro.loc[bool_test, 'lineage_assignment'].values[0], ncbi.get_taxid_translator(ncbi.get_lineage(2162565))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check lineage assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_mismatch = []\n",
    "taxids = marmicro['taxid'].values\n",
    "linassgns = marmicro['lineage_assignment'].values\n",
    "for t, l in zip(taxids, linassgns):\n",
    "    if t != 'NA':\n",
    "        t_ncbi = ncbi.get_taxid_translator([t])[int(t)]\n",
    "        lin_marmicro = l.split(';')\n",
    "        match = 0\n",
    "        for tm in lin_marmicro:\n",
    "            if tm in t_ncbi:\n",
    "                match = 1\n",
    "        if not match:\n",
    "            tax_mismatch.append([t, t_ncbi, l])\n",
    "\n",
    "len(tax_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Bathyarchaeota' in 'Candidatus Bathyarchaeota archaeon UBA185'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_ncbi, lin_marmicro[-1], ncbi.get_taxid_translator([t])[int(t)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of failed to fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2f = '''2182663\n",
    "2182826\n",
    "2182663\n",
    "2182663\n",
    "2182826\n",
    "2182826\n",
    "2182863\n",
    "2182863\n",
    "2182663\n",
    "2183026\n",
    "2183027\n",
    "2183026\n",
    "2183026\n",
    "2183026\n",
    "2182863\n",
    "2183014'''\n",
    "f2f = set(f2f.split('\\n'))\n",
    "\n",
    "for t in f2f:\n",
    "    print(t)\n",
    "    bool_test = marmicro['MARMICRODBtaxid'] == t\n",
    "    print(marmicro[bool_test].values)\n",
    "    bool_test = marmicro['taxid'] == t\n",
    "    print('\\n',marmicro[bool_test].values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many mmdbtaxids don't have ncbi taxids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "marmicro.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_noncbi =[]\n",
    "taxids = marmicro['MARMICRODBtaxid'].values\n",
    "for idx, t in enumerate(taxids):\n",
    "    try:\n",
    "        d = ncbi.get_taxid_translator([t])\n",
    "        if not d:\n",
    "            idx_noncbi.append(idx)\n",
    "    except:\n",
    "        idx_noncbi.append(idx)\n",
    "\n",
    "marmicro.iloc[idx_noncbi, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare old diamond run to fixed run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEst files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tax = '/mnt/nfs/projects/armbrust-metat/gradients2/g2_station_ns_metat/assemblies/MarMicro_MarFerr_Diamond_2024_04_14/G2NS.S02C1.15m.0_2um.MarFer_MMDB.tab'\n",
    "fn_ec = '/mnt/nfs/projects/armbrust-metat/gradients2/g2_station_ns_metat/assemblies/ReadCounts/G2NS.S02C1.15m.0_2um.A/G2NS.S02C1.15m.0_2um.A.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get taxa dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_contigs = defaultdict(list)\n",
    "with open(fn_tax, 'r') as f:\n",
    "    for row in f:\n",
    "        contig, taxid, _ = row.split('\\t')\n",
    "        dict_tax_contigs[taxid].append(contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_tax_contigs['131567']), len(dict_tax_contigs['35679'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get estcounts dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig_ec = {}\n",
    "with open(fn_ec, 'r') as f:\n",
    "    _ = next(f)\n",
    "    for row in f:\n",
    "        contig, _, _, ec, _ = row.split('\\t')\n",
    "        dict_contig_ec[contig] = ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get estcounts for each taxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_ec = {}\n",
    "for tax, contigs in dict_tax_contigs.items():\n",
    "    ec_sum = 0\n",
    "    for c in contigs:\n",
    "        ec = dict_contig_ec.get(c)\n",
    "        if ec:\n",
    "            ec_sum += float(ec)\n",
    "    dict_tax_ec[tax] = ec_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxids = [t for t in dict_tax_ec.keys() if int(t) > 0]\n",
    "tree = ncbi.get_topology(taxids)\n",
    "for n in tree.traverse():\n",
    "    ec = dict_tax_ec.get(n.name)\n",
    "    n.add_props(estcounts=ec)\n",
    "\n",
    "print(tree.to_str(props=['sci_name','estcounts'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction of reads at each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ec = sum([ec for ec in dict_tax_ec.values()])\n",
    "for n in tree.traverse():\n",
    "    ec_sum = 0\n",
    "    for n_d in n.descendants():\n",
    "        ec = n_d.props['estcounts']\n",
    "        if ec:\n",
    "            ec_sum += ec\n",
    "    n.add_props(ec_descendants=round(ec_sum), pct_ec=str(round(ec_sum/total_ec*100,4)) + '%')\n",
    "\n",
    "print(tree.to_str(props=['sci_name','ec_descendants', 'pct_ec'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_ecstuff = {}\n",
    "taxids_trim = []\n",
    "for n in tree.traverse():\n",
    "    pct_ec = float(n.props['ec_descendants'])\n",
    "    if pct_ec > 0:\n",
    "        taxids_trim.append(n.name)\n",
    "        dict_tax_ecstuff[n.name] = [n.props['ec_descendants'], n.props['pct_ec']]\n",
    "\n",
    "tree_trim = ncbi.get_topology(taxids_trim)\n",
    "for n in tree_trim.traverse():\n",
    "    ed, pe = dict_tax_ecstuff[n.name]\n",
    "    n.add_props(ec_descendants=ed, pct_ec=pe)\n",
    "\n",
    "print(tree_trim.to_str(props=['sci_name','ec_descendants', 'pct_ec'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_ecstuff = {}\n",
    "taxids_trim = []\n",
    "for n in tree.traverse():\n",
    "    pct_ec = float(n.props['pct_ec'].strip('%'))\n",
    "    if pct_ec > 0.1:\n",
    "        taxids_trim.append(n.name)\n",
    "        dict_tax_ecstuff[n.name] = [n.props['ec_descendants'], n.props['pct_ec']]\n",
    "\n",
    "tree_trim = ncbi.get_topology(taxids_trim)\n",
    "for n in tree_trim.traverse():\n",
    "    ed, pe = dict_tax_ecstuff[n.name]\n",
    "    n.add_props(ec_descendants=ed, pct_ec=pe)\n",
    "\n",
    "print(tree_trim.to_str(props=['sci_name','ec_descendants', 'pct_ec'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
