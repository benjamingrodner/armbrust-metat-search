{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work out how to deal with taxonomy\n",
    "\n",
    "Given contigs with taxonomy and KOs of interest, wth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import umap\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from collections import * \n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "from ete4 import NCBITaxa, Tree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../repo-armbrust-metat-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.fn_metat_files as fnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/scratch/bgrodner/iron_ko_contigs'\n",
    "os.chdir(workdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_plot(\n",
    "    xlabel=\"\", ylabel=\"\", ft=12, dims=(5, 3), col=\"k\", lw=1, pad=0, tr_spines=True\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(dims[0], dims[1]), tight_layout={\"pad\": pad})\n",
    "    for i in ax.spines:\n",
    "        ax.spines[i].set_linewidth(lw)\n",
    "    if not tr_spines:\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "    else:\n",
    "        ax.spines[\"top\"].set_color(col)\n",
    "        ax.spines[\"right\"].set_color(col)\n",
    "    ax.spines[\"bottom\"].set_color(col)\n",
    "    ax.spines[\"left\"].set_color(col)\n",
    "    ax.tick_params(direction=\"in\", labelsize=ft, color=col, labelcolor=col)\n",
    "    ax.set_xlabel(xlabel, fontsize=ft, color=col)\n",
    "    ax.set_ylabel(ylabel, fontsize=ft, color=col)\n",
    "    ax.patch.set_alpha(0)\n",
    "    return (fig, ax)\n",
    "\n",
    "def plot_umap(\n",
    "    embedding,\n",
    "    figsize=(10, 10),\n",
    "    markersize=10,\n",
    "    alpha=0.5,\n",
    "    colors=\"k\",\n",
    "    xticks=[],\n",
    "    yticks=[],\n",
    "    markerstyle='o',\n",
    "    cmap_name='tab20',\n",
    "    cl_lab=False\n",
    "):\n",
    "    fig, ax = general_plot(dims=figsize)\n",
    "    if isinstance(markerstyle, str):\n",
    "        ax.scatter(\n",
    "            embedding[:, 0],\n",
    "            embedding[:, 1],\n",
    "            s=markersize,\n",
    "            alpha=alpha,\n",
    "            c=colors,\n",
    "            edgecolors=\"none\",\n",
    "            marker=markerstyle,\n",
    "            cmap=cmap_name\n",
    "        )\n",
    "    else:\n",
    "        for e0, e1, c, m in zip(\n",
    "            embedding[:, 0], \n",
    "            embedding[:, 1],\n",
    "            colors,\n",
    "            markerstyle \n",
    "        ):\n",
    "            ax.scatter(\n",
    "                e0,\n",
    "                e1,\n",
    "                s=markersize,\n",
    "                alpha=alpha,\n",
    "                c=c,\n",
    "                edgecolors=\"none\",\n",
    "                marker=m\n",
    "            )\n",
    "    ax.set_aspect(\"equal\")\n",
    "    if len(xticks) > 0:\n",
    "        ax.set_xticks(xticks)\n",
    "    if len(yticks) > 0:\n",
    "        ax.set_yticks(yticks)\n",
    "    ax.set_xlabel(\"UMAP 1\")\n",
    "    ax.set_ylabel(\"UMAP 2\")\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get KO dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_fn = \"ko00001.json\"\n",
    "database = list()\n",
    "for _, v in pd.read_json(ko_fn).iterrows():\n",
    "    d = v[\"children\"]\n",
    "    cat_1 = d[\"name\"]\n",
    "    for child_1 in d[\"children\"]:\n",
    "        cat_2 = child_1[\"name\"] # Module?\n",
    "        for child_2 in child_1[\"children\"]:\n",
    "            cat_3 = child_2[\"name\"]\n",
    "            if \"children\" in child_2:\n",
    "                for child_3 in child_2[\"children\"]:\n",
    "                    cat_4 = child_3[\"name\"]\n",
    "                    fields = [cat_1, cat_2, cat_3, cat_4]\n",
    "                    database.append(fields)\n",
    "df_kegg = pd.DataFrame(database, columns=[\"Level_A\", \"Level_B\", \"Level_C\", \"Level_D\"])\n",
    "df_kegg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = df_kegg['Level_D'].values\n",
    "ld[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_name = {}\n",
    "for name in ld:\n",
    "    ko = re.search(r\"^\\w+\",name)[0]\n",
    "    dict_ko_name[ko] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get taxa for ko of interest\n",
    "\n",
    "Load taxa file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_tax = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_tax'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'{dir_tax}/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-df_contig_full_taxonomy.csv'\n",
    "df_tax = pd.read_csv(fn, dtype=str, keep_default_na=False)\n",
    "df_tax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax.iloc[:3,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load contig taxid dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_dict_contig_tax = f'{dir_tax}/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-dict_contig_taxid.json'\n",
    "fnf.getmem()\n",
    "with open(fn_dict_contig_tax, 'r') as f:\n",
    "    dict_contig_tax = json.load(f)\n",
    "fnf.getmem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dict ko conitgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ko_dict = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig'\n",
    "fn_dict = f'{dir_ko_dict}/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-dict.json'\n",
    "fnf.getmem()\n",
    "with open(fn_dict, 'r') as f:\n",
    "    dict_ko_contigs = json.load(f)\n",
    "fnf.getmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax['contig'][:5], dict_ko_contigs[list(dict_ko_contigs.keys())[0]][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO of interest\n",
    "\n",
    "`KO: K14716  SLC39A10, ZIP10; solute carrier family 39 (zinc transporter), member 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = 'K14716'\n",
    "\n",
    "contigs = dict_ko_contigs[ko]\n",
    "\n",
    "list_tax_ko = []\n",
    "for i, row in df_tax.iterrows():\n",
    "    if row.contig in set(contigs):\n",
    "        list_tax_ko.append(row.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax_ko = pd.DataFrame(np.vstack(list_tax_ko), columns=df_tax.columns)\n",
    "df_tax_ko.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many contigs are taxon annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_annotated = []\n",
    "for c_vals in df_tax_ko.values[:,1:]:\n",
    "    n_annotated.append(c_vals.astype(bool).sum() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(np.arange(len(n_annotated)), np.sort(n_annotated))\n",
    "xlims = ax.get_xlim()\n",
    "ax.set_ylabel('Number of taxa levels annotated')\n",
    "ax.set_xlabel('Contig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxids = []\n",
    "for c in contigs:\n",
    "    t = dict_contig_tax[c][0]\n",
    "    if int(t):\n",
    "        try:\n",
    "            ncbi.get_lineage(t)\n",
    "            taxids.append(t)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "tree = ncbi.get_topology(taxids)\n",
    "# Add counts\n",
    "tax_unq, tax_count = np.unique(taxids, return_counts=True)\n",
    "dict_tax_count = dict(zip(tax_unq, tax_count))\n",
    "for n in tree:\n",
    "    n.add_props(count=dict_tax_count[n.name])\n",
    "\n",
    "print(tree.to_str(props=['sci_name','count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ncbi.get_topology(taxids)\n",
    "\n",
    "tree.descendants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO of interest\n",
    "\n",
    "`KO: K02639  petF; ferredoxin`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = 'K02639'\n",
    "\n",
    "contigs = dict_ko_contigs[ko]\n",
    "\n",
    "list_tax_ko = []\n",
    "for i, row in df_tax.iterrows():\n",
    "    if row.contig in set(contigs):\n",
    "        list_tax_ko.append(row.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax_ko = pd.DataFrame(np.vstack(list_tax_ko), columns=df_tax.columns)\n",
    "df_tax_ko.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many contigs are taxon annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_annotated = []\n",
    "for c_vals in df_tax_ko.values[:,1:]:\n",
    "    n_annotated.append(c_vals.astype(bool).sum() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(np.arange(len(n_annotated)), np.sort(n_annotated))\n",
    "xlims = ax.get_xlim()\n",
    "ax.set_ylabel('Number of taxa levels annotated')\n",
    "ax.set_xlabel('Contig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxids = []\n",
    "for c in contigs:\n",
    "    t = dict_contig_tax[c][0]\n",
    "    if int(t):\n",
    "        try:\n",
    "            ncbi.get_lineage(t)\n",
    "            taxids.append(t)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "tree = ncbi.get_topology(taxids)\n",
    "# Add counts\n",
    "tax_unq, tax_count = np.unique(taxids, return_counts=True)\n",
    "dict_tax_count = dict(zip(tax_unq, tax_count))\n",
    "for n in tree:\n",
    "    n.add_props(count=dict_tax_count[n.name])\n",
    "\n",
    "print(tree.to_str(props=['sci_name','count'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO of interest\n",
    "\n",
    "`KO: K01624  FBA, fbaA; fructose-bisphosphate aldolase, class II [EC:4.1.2.13]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = 'K01624'\n",
    "\n",
    "contigs = dict_ko_contigs[ko]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_tax_ko = []\n",
    "for i, row in df_tax.iterrows():\n",
    "    if row.contig in set(contigs):\n",
    "        list_tax_ko.append(row.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax_ko = pd.DataFrame(np.vstack(list_tax_ko), columns=df_tax.columns)\n",
    "df_tax_ko.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many contigs are taxon annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_annotated = []\n",
    "for c_vals in df_tax_ko.values[:,1:]:\n",
    "    n_annotated.append(c_vals.astype(bool).sum() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(np.arange(len(n_annotated)), np.sort(n_annotated))\n",
    "xlims = ax.get_xlim()\n",
    "ax.set_ylabel('Number of taxa levels annotated')\n",
    "ax.set_xlabel('Contig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get taxids for KO\n",
    "taxids = []\n",
    "for c in contigs:\n",
    "    t = dict_contig_tax[c][0]\n",
    "    if int(t):\n",
    "        try:\n",
    "            ncbi.get_lineage(t)\n",
    "            taxids.append(t)\n",
    "        except:\n",
    "            pass\n",
    "# Build tree\n",
    "tree = ncbi.get_topology(taxids)\n",
    "# Add counts at each internal node\n",
    "lineages = [ncbi.get_lineage(t) for t in taxids]\n",
    "taxids_lin = list(itertools.chain(*lineages))\n",
    "tax_unq, tax_count = np.unique(taxids_lin, return_counts=True)\n",
    "dict_tax_count = dict(zip(tax_unq, tax_count))\n",
    "for n in tree.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_count[tax])\n",
    "\n",
    "print(tree.to_str(props=['sci_name','count'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KO of interest\n",
    "\n",
    "`KO: K03320  amt, AMT, MEP; ammonium transporter, Amt family`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = 'K03320'\n",
    "\n",
    "contigs = dict_ko_contigs[ko]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get taxon lineage table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_tax_ko = []\n",
    "for i, row in df_tax.iterrows():\n",
    "    if row.contig in set(contigs):\n",
    "        list_tax_ko.append(row.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax_ko = pd.DataFrame(np.vstack(list_tax_ko), columns=df_tax.columns)\n",
    "df_tax_ko.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many contigs are taxon annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_annotated = []\n",
    "for c_vals in df_tax_ko.values[:,1:]:\n",
    "    n_annotated.append(c_vals.astype(bool).sum() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot()\n",
    "ax.scatter(np.arange(len(n_annotated)), np.sort(n_annotated))\n",
    "xlims = ax.get_xlim()\n",
    "ax.set_ylabel('Number of taxa levels annotated')\n",
    "ax.set_xlabel('Contig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get taxids for KO\n",
    "taxids = []\n",
    "for c in contigs:\n",
    "    t = dict_contig_tax[c][0]\n",
    "    if int(t):\n",
    "        try:\n",
    "            ncbi.get_lineage(t)\n",
    "            taxids.append(t)\n",
    "        except:\n",
    "            pass\n",
    "# Build tree\n",
    "tree = ncbi.get_topology(taxids)\n",
    "# Add counts at each internal node\n",
    "lineages = [ncbi.get_lineage(t) for t in taxids]\n",
    "taxids_lin = list(itertools.chain(*lineages))\n",
    "tax_unq, tax_count = np.unique(taxids_lin, return_counts=True)\n",
    "dict_tax_count = dict(zip(tax_unq, tax_count))\n",
    "for n in tree.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_count[tax])\n",
    "\n",
    "print(tree.to_str(props=['sci_name','count'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick taxonomic levels with counts across multiple samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get full taxonomic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full tax list\n",
    "taxids_all = []\n",
    "for t in dict_contig_tax.values():\n",
    "    t = t[0]\n",
    "    if int(t):\n",
    "        try:\n",
    "            ncbi.get_lineage(t)\n",
    "            taxids_all.append(t)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "set_taxids = set(taxids_all)\n",
    "len(set_taxids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ncbi.get_topology(set_taxids)\n",
    "print(tree.to_str(props=['name', 'sci_name'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict taxid -> contig list (for full lineage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_contigs = defaultdict(list)\n",
    "for c, t in dict_contig_tax.items():\n",
    "    if t[0] in set_taxids:\n",
    "        lin = ncbi.get_lineage(t[0])\n",
    "        for l in lin:\n",
    "            dict_tax_contigs[l].append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict contig -> KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig_ko = {}\n",
    "for ko, contigs in dict_ko_contigs.items():\n",
    "    for c in contigs:\n",
    "        dict_contig_ko[c] = ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick an example leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf = 637379  # T. oceanica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given taxid, get number of different KOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigs = dict_tax_contigs[leaf]\n",
    "kos = [dict_contig_ko[c] for c in contigs]\n",
    "set_kos = set(kos)\n",
    "set_kos, len(contigs), len(set(contigs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict contig -> sample counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of sample names\n",
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "dict_contig_counts = defaultdict(list)\n",
    "samples = []\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "        # Load counts\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        for c in contigs:\n",
    "            c_ = re.sub(r'_\\d+$','',c)\n",
    "            # map contig to counts\n",
    "            dict_contig_counts[c].append(dict_ctg_cnt[c_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build out dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "for c in contigs:\n",
    "    ko = dict_contig_ko[c]\n",
    "    df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dict_ko_contigs['K01726']).intersection(set(contigs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk up through the lineage of the leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "dfs = {}\n",
    "# Get leaf\n",
    "print(leaf)\n",
    "# Kos and contigs\n",
    "contigs = dict_tax_contigs[leaf]\n",
    "kos = [dict_contig_ko[c] for c in contigs]\n",
    "set_kos = set(kos)\n",
    "# Dict contig -> sample counts\n",
    "dict_contig_counts = defaultdict(list)\n",
    "samples = []\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "        # Load counts\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        for c in contigs:\n",
    "            c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "            # map contig to counts\n",
    "            dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "# Build out dataframe\n",
    "df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "for c in contigs:\n",
    "    ko = dict_contig_ko[c]\n",
    "    df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "dfs[leaf] = (df_taxid)\n",
    "# Get ancestors of leaf\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < 6:\n",
    "        print(n.name)\n",
    "        # Kos and contigs\n",
    "        contigs = dict_tax_contigs[int(n.name)]\n",
    "        kos = [dict_contig_ko[c] for c in contigs]\n",
    "        set_kos = set(kos)\n",
    "        # Dict contig -> sample counts\n",
    "        dict_contig_counts = defaultdict(list)\n",
    "        samples = []\n",
    "        for fn in fns:\n",
    "            if '_3um' in fn:\n",
    "                samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "                # Load counts\n",
    "                df = pd.read_csv(fn)\n",
    "                ctg = df.iloc[:,0].values\n",
    "                cnt = df.iloc[:,1].values\n",
    "                dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "                for c in contigs:\n",
    "                    c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "                    # map contig to counts\n",
    "                    dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "        # Build out dataframe\n",
    "        df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "        for c in contigs:\n",
    "            ko = dict_contig_ko[c]\n",
    "            df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "        dfs[n.name] = (df_taxid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs[637379]\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs['35127']\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs['29202']\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs['33847']\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs['33846']\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs['33836']\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid = dfs['2836']\n",
    "print(df_taxid.shape)\n",
    "df_taxid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info on count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_names = []\n",
    "n_ko = []\n",
    "frac_sam_filled = []\n",
    "\n",
    "df = dfs[leaf]\n",
    "scn = ncbi.get_rank([leaf])[leaf] + ' ' + ncbi.get_taxid_translator([str(leaf)])[leaf]\n",
    "sci_names.append(scn)\n",
    "n_ko.append(df.shape[1])\n",
    "fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "frac_sam_filled.append(fracs)\n",
    "\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < 6:\n",
    "        tid = n.name\n",
    "        df = dfs[tid]\n",
    "        scn = ncbi.get_rank([tid])[int(tid)] + ' ' + ncbi.get_taxid_translator([str(tid)])[int(tid)]\n",
    "        sci_names.append(scn)\n",
    "        n_ko.append(df.shape[1])\n",
    "        fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "        frac_sam_filled.append(fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator([str(leaf)])[leaf]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot number of kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "x = np.arange(len(n_ko))\n",
    "ax.plot(x, n_ko)\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Number of KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fraction of samples with counts in each KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "markersize=2\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "ax.boxplot(frac_sam_filled)\n",
    "for _x, fsf in enumerate(frac_sam_filled):\n",
    "    _x += (np.random.rand(len(fsf)) - 0.5) * 0.25 + 1\n",
    "    ax.scatter(_x, fsf, s=markersize, c='k')\n",
    "x = np.arange(len(n_ko)) + 1\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Fraction of samples\\nwith counts for each KO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check another leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf = 2802065 #,Chrysochromulina sp. KB-HA01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "dfs = {}\n",
    "# Get leaf\n",
    "print(leaf)\n",
    "# Kos and contigs\n",
    "contigs = dict_tax_contigs[leaf]\n",
    "kos = [dict_contig_ko[c] for c in contigs]\n",
    "set_kos = set(kos)\n",
    "# Dict contig -> sample counts\n",
    "dict_contig_counts = defaultdict(list)\n",
    "samples = []\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "        # Load counts\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        for c in contigs:\n",
    "            c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "            # map contig to counts\n",
    "            dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "# Build out dataframe\n",
    "df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "for c in contigs:\n",
    "    ko = dict_contig_ko[c]\n",
    "    df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "dfs[leaf] = (df_taxid)\n",
    "# Get ancestors of leaf\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < 100:\n",
    "        print(n.name)\n",
    "        # Kos and contigs\n",
    "        contigs = dict_tax_contigs[int(n.name)]\n",
    "        kos = [dict_contig_ko[c] for c in contigs]\n",
    "        set_kos = set(kos)\n",
    "        # Dict contig -> sample counts\n",
    "        dict_contig_counts = defaultdict(list)\n",
    "        samples = []\n",
    "        for fn in fns:\n",
    "            if '_3um' in fn:\n",
    "                samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "                # Load counts\n",
    "                df = pd.read_csv(fn)\n",
    "                ctg = df.iloc[:,0].values\n",
    "                cnt = df.iloc[:,1].values\n",
    "                dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "                for c in contigs:\n",
    "                    c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "                    # map contig to counts\n",
    "                    dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "        # Build out dataframe\n",
    "        df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "        for c in contigs:\n",
    "            ko = dict_contig_ko[c]\n",
    "            df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "        dfs[n.name] = (df_taxid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info on count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_names = []\n",
    "n_ko = []\n",
    "frac_sam_filled = []\n",
    "\n",
    "df = dfs[leaf]\n",
    "scn = ncbi.get_rank([leaf])[leaf] + ' ' + ncbi.get_taxid_translator([str(leaf)])[leaf]\n",
    "sci_names.append(scn)\n",
    "n_ko.append(df.shape[1])\n",
    "fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "frac_sam_filled.append(fracs)\n",
    "\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < 6:\n",
    "        tid = n.name\n",
    "        df = dfs[tid]\n",
    "        scn = ncbi.get_rank([tid])[int(tid)] + ' ' + ncbi.get_taxid_translator([str(tid)])[int(tid)]\n",
    "        sci_names.append(scn)\n",
    "        n_ko.append(df.shape[1])\n",
    "        fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "        frac_sam_filled.append(fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator([str(leaf)])[leaf]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot number of kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "x = np.arange(len(n_ko))\n",
    "ax.plot(x, n_ko)\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Number of KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fraction of samples with counts in each KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "markersize=2\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "ax.boxplot(frac_sam_filled)\n",
    "for _x, fsf in enumerate(frac_sam_filled):\n",
    "    _x += (np.random.rand(len(fsf)) - 0.5) * 0.25 + 1\n",
    "    ax.scatter(_x, fsf, s=markersize, c='k')\n",
    "x = np.arange(len(n_ko)) + 1\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Fraction of samples\\nwith counts for each KO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check another leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf = 413974 #,Chlamydomonas sp. CCMP681\n",
    "n_level = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "dfs = {}\n",
    "# Get leaf\n",
    "print(leaf)\n",
    "# Kos and contigs\n",
    "contigs = dict_tax_contigs[leaf]\n",
    "kos = [dict_contig_ko[c] for c in contigs]\n",
    "set_kos = set(kos)\n",
    "# Dict contig -> sample counts\n",
    "dict_contig_counts = defaultdict(list)\n",
    "samples = []\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "        # Load counts\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        for c in contigs:\n",
    "            c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "            # map contig to counts\n",
    "            dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "# Build out dataframe\n",
    "df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "for c in contigs:\n",
    "    ko = dict_contig_ko[c]\n",
    "    df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "dfs[leaf] = (df_taxid)\n",
    "# Get ancestors of leaf\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < n_level:\n",
    "        print(n.name)\n",
    "        # Kos and contigs\n",
    "        contigs = dict_tax_contigs[int(n.name)]\n",
    "        kos = [dict_contig_ko[c] for c in contigs]\n",
    "        set_kos = set(kos)\n",
    "        # Dict contig -> sample counts\n",
    "        dict_contig_counts = defaultdict(list)\n",
    "        samples = []\n",
    "        for fn in fns:\n",
    "            if '_3um' in fn:\n",
    "                samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "                # Load counts\n",
    "                df = pd.read_csv(fn)\n",
    "                ctg = df.iloc[:,0].values\n",
    "                cnt = df.iloc[:,1].values\n",
    "                dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "                for c in contigs:\n",
    "                    c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "                    # map contig to counts\n",
    "                    dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "        # Build out dataframe\n",
    "        df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "        for c in contigs:\n",
    "            ko = dict_contig_ko[c]\n",
    "            df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "        dfs[n.name] = (df_taxid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info on count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_names = []\n",
    "n_ko = []\n",
    "frac_sam_filled = []\n",
    "\n",
    "df = dfs[leaf]\n",
    "scn = ncbi.get_rank([leaf])[leaf] + ' ' + ncbi.get_taxid_translator([str(leaf)])[leaf]\n",
    "sci_names.append(scn)\n",
    "n_ko.append(df.shape[1])\n",
    "fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "frac_sam_filled.append(fracs)\n",
    "\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < n_level:\n",
    "        tid = n.name\n",
    "        df = dfs[n.name]\n",
    "        scn = ncbi.get_rank([tid])[int(tid)] + ' ' + ncbi.get_taxid_translator([str(tid)])[int(tid)]\n",
    "        sci_names.append(scn)\n",
    "        n_ko.append(df.shape[1])\n",
    "        fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "        frac_sam_filled.append(fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator([str(leaf)])[leaf]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot number of kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "x = np.arange(len(n_ko))\n",
    "ax.plot(x, n_ko)\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Number of KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fraction of samples with counts in each KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "markersize=2\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "ax.boxplot(frac_sam_filled)\n",
    "for _x, fsf in enumerate(frac_sam_filled):\n",
    "    _x += (np.random.rand(len(fsf)) - 0.5) * 0.25 + 1\n",
    "    ax.scatter(_x, fsf, s=markersize, c='k')\n",
    "x = np.arange(len(n_ko)) + 1\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Fraction of samples\\nwith counts for each KO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check another leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf = 174948 # Symbiodinium sp. CCMP421\n",
    "n_level = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "dfs = {}\n",
    "# Get leaf\n",
    "print(leaf)\n",
    "# Kos and contigs\n",
    "contigs = dict_tax_contigs[leaf]\n",
    "kos = [dict_contig_ko[c] for c in contigs]\n",
    "set_kos = set(kos)\n",
    "# Dict contig -> sample counts\n",
    "dict_contig_counts = defaultdict(list)\n",
    "samples = []\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "        # Load counts\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        for c in contigs:\n",
    "            c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "            # map contig to counts\n",
    "            dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "# Build out dataframe\n",
    "df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "for c in contigs:\n",
    "    ko = dict_contig_ko[c]\n",
    "    df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "dfs[leaf] = (df_taxid)\n",
    "# Get ancestors of leaf\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < n_level:\n",
    "        print(n.name)\n",
    "        # Kos and contigs\n",
    "        contigs = dict_tax_contigs[int(n.name)]\n",
    "        kos = [dict_contig_ko[c] for c in contigs]\n",
    "        set_kos = set(kos)\n",
    "        # Dict contig -> sample counts\n",
    "        dict_contig_counts = defaultdict(list)\n",
    "        samples = []\n",
    "        for fn in fns:\n",
    "            if '_3um' in fn:\n",
    "                samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "                # Load counts\n",
    "                df = pd.read_csv(fn)\n",
    "                ctg = df.iloc[:,0].values\n",
    "                cnt = df.iloc[:,1].values\n",
    "                dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "                for c in contigs:\n",
    "                    c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "                    # map contig to counts\n",
    "                    dict_contig_counts[c].append(dict_ctg_cnt[c_])\n",
    "        # Build out dataframe\n",
    "        df_taxid = pd.DataFrame(0, columns=list(set_kos), index=samples)\n",
    "        for c in contigs:\n",
    "            ko = dict_contig_ko[c]\n",
    "            df_taxid[ko] += np.array(dict_contig_counts[c])\n",
    "        dfs[n.name] = (df_taxid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info on count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_names = []\n",
    "n_ko = []\n",
    "frac_sam_filled = []\n",
    "\n",
    "df = dfs[leaf]\n",
    "scn = ncbi.get_rank([leaf])[leaf] + ' ' + ncbi.get_taxid_translator([str(leaf)])[leaf]\n",
    "sci_names.append(scn)\n",
    "n_ko.append(df.shape[1])\n",
    "fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "frac_sam_filled.append(fracs)\n",
    "\n",
    "for i, n in enumerate(tree[str(leaf)].ancestors()):\n",
    "    if i < n_level:\n",
    "        df = dfs[n.name]\n",
    "        tid = n.name\n",
    "        scn = ncbi.get_rank([tid])[int(tid)] + ' ' + ncbi.get_taxid_translator([str(tid)])[int(tid)]\n",
    "        sci_names.append(scn)\n",
    "        n_ko.append(df.shape[1])\n",
    "        fracs = df.values.astype(bool).sum(axis=0) / df.shape[0]\n",
    "        frac_sam_filled.append(fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi.get_taxid_translator([str(leaf)])[leaf]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot number of kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "x = np.arange(len(n_ko))\n",
    "ax.plot(x, n_ko)\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Number of KOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fraction of samples with counts in each KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=8\n",
    "dims=(4,4)\n",
    "markersize=2\n",
    "fig, ax = general_plot(ft=ft, dims=dims)\n",
    "ax.boxplot(frac_sam_filled)\n",
    "for _x, fsf in enumerate(frac_sam_filled):\n",
    "    _x += (np.random.rand(len(fsf)) - 0.5) * 0.25 + 1\n",
    "    ax.scatter(_x, fsf, s=markersize, c='k')\n",
    "x = np.arange(len(n_ko)) + 1\n",
    "_ = ax.set_xticks(x)\n",
    "_ = ax.set_xticklabels(sci_names, rotation=45, ha='right', rotation_mode='anchor')\n",
    "_ = ax.set_ylabel('Fraction of samples\\nwith counts for each KO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write code for full tree based on KO count and frac sample filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(tree.leaf_names())), len(list(tree.descendants()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that internal nodes are nort in leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alveolata clade\n",
    "('33630' in list(tree.leaf_names())), ('33630' in [n.name for n in tree.descendants()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write snakeamke rule to trim leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf = 2802065 #,Chrysochromulina sp. KB-HA01\n",
    "\n",
    "thresh_n_kos = 20\n",
    "thresh_mff = 0.2\n",
    "\n",
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "\n",
    "lineage = [str(leaf)] + [n.name for n in tree[str(leaf)].ancestors()]\n",
    "dict_lin_nkos = {}\n",
    "dict_lin_ko_cnts = defaultdict(lambda: defaultdict(list))\n",
    "# Load dict_tax_contigs, dict_contig_ko\n",
    "\n",
    "# Get number of kos for each lineage\n",
    "for l in lineage:\n",
    "    contigs = dict_tax_contigs[int(l)]\n",
    "    kos = [dict_contig_ko[c] for c in contigs]\n",
    "    # add number of kos to lineage info\n",
    "    set_kos = set(kos)\n",
    "    dict_lin_nkos[l] = len(set_kos)\n",
    "\n",
    "# Get KO counts for each sample\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        # Load dict_contig_count\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        # Count each lineage\n",
    "        # n_kos = 0\n",
    "        # mean_frac_fill = 0\n",
    "        for l in lineage:\n",
    "            # if (n_kos < thresh_n_kos) or (mean_frac_fill < thresh_mff):\n",
    "            contigs = dict_tax_contigs[int(l)]\n",
    "            # counts and kos\n",
    "            dict_ko_cnt = defaultdict(lambda: 0)\n",
    "            for c in contigs:\n",
    "                ko = dict_contig_ko[c]\n",
    "                c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "                dict_ko_cnt[ko] += dict_ctg_cnt[c_]\n",
    "            # Add ko count to lineage info\n",
    "            for ko, cnt in dict_ko_cnt.items():\n",
    "                dict_lin_ko_cnts[l][ko].append(cnt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lineage:\n",
    "    print('\\n',l)\n",
    "    print(dict_lin_nkos[l])\n",
    "    frac_kos = []\n",
    "    for ko, counts in dict_lin_ko_cnts[l].items():\n",
    "        frac = np.array(counts).astype(bool).sum()\n",
    "        frac_kos.append(frac)\n",
    "    print(np.mean(frac_kos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid = 236786  # Florenciella\n",
    "\n",
    "contigs = dict_tax_contigs[taxid]\n",
    "kos = set(dict_contig_ko[c] for c in contigs)\n",
    "ko_names = [dict_ko_name[k] for k in kos]\n",
    "ko_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the fraction of contigs captured by a set of leaves "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get counts for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank = ncbi.get_rank([n.name])[n.name]\n",
    "\n",
    "# Add counts at each internal node\n",
    "lineages = [ncbi.get_lineage(t) for t in taxids_all]\n",
    "taxids_lin = list(itertools.chain(*lineages))\n",
    "tax_unq, tax_count = np.unique(taxids_lin, return_counts=True)\n",
    "dict_tax_contigcount = dict(zip(tax_unq, tax_count))\n",
    "for n in tree.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(n_contigs=dict_tax_contigcount[tax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get total number of contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_contigs = len(taxids_all)\n",
    "n_contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get fraction with max leaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_count = 0\n",
    "for n in tree.leaves():\n",
    "    c_count += n.props['count']\n",
    "\n",
    "frac = c_count / n_contigs\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction trimmed to genus level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_genus = ncbi.get_topology(set_taxids, rank_limit='genus')\n",
    "\n",
    "# Add contig counts\n",
    "for n in tree_genus.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_contigcount[tax])\n",
    "\n",
    "c_count = 0\n",
    "for n in tree_genus.leaves():\n",
    "    c_count += n.props['count']\n",
    "\n",
    "frac = c_count / n_contigs\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction trimmed to family level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fam = ncbi.get_topology(set_taxids, rank_limit='family')\n",
    "\n",
    "# Add contig counts\n",
    "for n in tree_fam.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_contigcount[tax])\n",
    "\n",
    "c_count = 0\n",
    "for n in tree_fam.leaves():\n",
    "    c_count += n.props['count']\n",
    "\n",
    "frac = c_count / n_contigs\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction trimmed to order level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ord = ncbi.get_topology(set_taxids, rank_limit='order')\n",
    "\n",
    "# Add contig counts\n",
    "for n in tree_ord.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_contigcount[tax])\n",
    "\n",
    "c_count = 0\n",
    "for n in tree_ord.leaves():\n",
    "    c_count += n.props['count']\n",
    "\n",
    "frac = c_count / n_contigs\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction trimmed to class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_class = ncbi.get_topology(set_taxids, rank_limit='class')\n",
    "\n",
    "# Add contig counts\n",
    "for n in tree_class.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_contigcount[tax])\n",
    "\n",
    "c_count = 0\n",
    "for n in tree_class.leaves():\n",
    "    c_count += n.props['count']\n",
    "\n",
    "frac = c_count / n_contigs\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction trimmed to phylum level (seems like trimming is not working properly since not all taxa have phylum annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_phy = ncbi.get_topology(set_taxids, rank_limit='phylum')\n",
    "\n",
    "# Add contig counts\n",
    "for n in tree_phy.traverse():\n",
    "    tax = int(n.name)\n",
    "    n.add_props(count=dict_tax_contigcount[tax])\n",
    "\n",
    "c_count = 0\n",
    "for n in tree_phy.leaves():\n",
    "    c_count += n.props['count']\n",
    "\n",
    "frac = c_count / n_contigs\n",
    "\n",
    "print(frac)\n",
    "print(tree_phy.to_str(props=['name', 'sci_name'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean number of samples filled across KOs for full tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values for each node in tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count/tables_norm_count/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tables_norm_count'\n",
    "glob_fn = f'{dir_counts}/*.tsv-table_norm_count.csv'\n",
    "fns = glob.glob(glob_fn)\n",
    "\n",
    "# lineage = [str(leaf)] + [n.name for n in tree[str(leaf)].ancestors()]\n",
    "dict_lin_nkos = {}\n",
    "dict_lin_ko_cnts = defaultdict(lambda: defaultdict(list))\n",
    "# Load dict_tax_contigs, dict_contig_ko\n",
    "\n",
    "# Get number of kos for each lineage\n",
    "for n in tree.traverse():\n",
    "    l = n.name\n",
    "    contigs = dict_tax_contigs[int(l)]\n",
    "    kos = [dict_contig_ko[c] for c in contigs]\n",
    "    # add number of kos to lineage info\n",
    "    set_kos = set(kos)\n",
    "    dict_lin_nkos[l] = len(set_kos)\n",
    "\n",
    "# Get KO counts for each sample\n",
    "for fn in tqdm(fns):\n",
    "    if '_3um' in fn:\n",
    "        # Load dict_contig_count\n",
    "        df = pd.read_csv(fn)\n",
    "        ctg = df.iloc[:,0].values\n",
    "        cnt = df.iloc[:,1].values\n",
    "        dict_ctg_cnt = dict(zip(ctg, cnt))\n",
    "        # Count each lineage\n",
    "        # n_kos = 0\n",
    "        # mean_frac_fill = 0\n",
    "        for n in tree.traverse():\n",
    "            l = n.name\n",
    "            # if (n_kos < thresh_n_kos) or (mean_frac_fill < thresh_mff):\n",
    "            contigs = dict_tax_contigs[int(l)]\n",
    "            # counts and kos\n",
    "            dict_ko_cnt = defaultdict(lambda: 0)\n",
    "            for c in contigs:\n",
    "                ko = dict_contig_ko[c]\n",
    "                c_ = re.sub(r'_\\d+$','',c)  # manage 6tr filenaming\n",
    "                dict_ko_cnt[ko] += dict_ctg_cnt[c_]\n",
    "            # Add ko count to lineage info\n",
    "            for ko, cnt in dict_ko_cnt.items():\n",
    "                dict_lin_ko_cnts[l][ko].append(cnt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict mapping taxid in tree to max and mean n samples across kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_lin_maxmeannsam = {}\n",
    "for n in tree.traverse():\n",
    "    l = n.name\n",
    "    n_sam = []\n",
    "    for ko, counts in dict_lin_ko_cnts[l].items():\n",
    "        ns = np.array(counts).astype(bool).sum()\n",
    "        n_sam.append(ns)\n",
    "    max_n_sam = np.max(n_sam)\n",
    "    mean_n_sam = np.round(np.mean(n_sam), 1)\n",
    "    dict_lin_maxmeannsam[l] = [max_n_sam, mean_n_sam]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot tree with n contigs, n kos, and max sample counts across kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tree.traverse():\n",
    "    l = n.name\n",
    "    n_contigs = dict_tax_contigcount[int(l)]\n",
    "    max_n_sam, meam_n_sam = dict_lin_maxmeannsam[l]\n",
    "    nkos = dict_lin_nkos[l]\n",
    "    n.add_props(\n",
    "        n_contigs=n_contigs, \n",
    "        max_n_sam=max_n_sam, \n",
    "        mean_n_sam=mean_n_sam, \n",
    "        nkos=nkos\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.to_str(props=['sci_name','n_contigs','nkos','max_n_sam'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.to_str(props=['sci_name','n_contigs','name'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at distributions of n contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_counts = []\n",
    "for n in tree.traverse():\n",
    "    l = int(n.name)\n",
    "    c_counts.append(dict_tax_contigcount[l])\n",
    "\n",
    "\n",
    "fig, ax = general_plot()\n",
    "_ = ax.hist(np.log(c_counts), bins=100)\n",
    "xlims = ax.get_xlim()\n",
    "xticks = np.arange(int(max(xlims)))\n",
    "_ = ax.set_xticks(xticks)\n",
    "xlab = [f'1e{l}' for l in xticks]\n",
    "_ = ax.set_xticklabels(xlab, fontsize=8)\n",
    "_ = ax.set_xlabel('Number of contigs in taxid')\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at distributions of n kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_counts = []\n",
    "for n in tree.traverse():\n",
    "    l = n.name\n",
    "    c_counts.append(dict_lin_nkos[l])\n",
    "\n",
    "\n",
    "fig, ax = general_plot()\n",
    "bins = np.arange(0,max(np.log(c_counts)),0.1)\n",
    "_ = ax.hist(np.log(c_counts), bins=bins)\n",
    "xlims = ax.get_xlim()\n",
    "xticks = np.arange(int(max(xlims)))\n",
    "_ = ax.set_xticks(xticks)\n",
    "xlab = [f'1e{l}' for l in xticks]\n",
    "_ = ax.set_xticklabels(xlab, fontsize=8)\n",
    "_ = ax.set_xlabel('Number of KOs in taxid')\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at distributions of max samples across kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_counts = []\n",
    "for n in tree.traverse():\n",
    "    l = n.name\n",
    "    c_counts.append(dict_lin_maxmeannsam[l][0])\n",
    "\n",
    "\n",
    "fig, ax = general_plot(ft=8)\n",
    "bins = np.arange(0,max(c_counts),1)\n",
    "_ = ax.hist(c_counts, bins=bins)\n",
    "xlims = ax.get_xlim()\n",
    "xticks = np.arange(int(max(xlims)))\n",
    "_ = ax.set_xticks(xticks)\n",
    "# xlab = [f'1e{l}' for l in xticks]\n",
    "# _ = ax.set_xticklabels(xlab, fontsize=8)\n",
    "# _ = ax.set_xticklabels(fontsize=8)\n",
    "_ = ax.set_xlabel('Max number of samples with nonzero counts across KOs in taxid')\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at distributions of mean samples across kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_counts = []\n",
    "for n in tree.traverse():\n",
    "    l = n.name\n",
    "    c_counts.append(dict_lin_maxmeannsam[l][1])\n",
    "\n",
    "\n",
    "fig, ax = general_plot(ft=8)\n",
    "bins = np.arange(0,max(c_counts),1)\n",
    "_ = ax.hist(c_counts, bins=bins)\n",
    "xlims = ax.get_xlim()\n",
    "xticks = np.arange(int(max(xlims)))\n",
    "_ = ax.set_xticks(xticks)\n",
    "# xlab = [f'1e{l}' for l in xticks]\n",
    "# _ = ax.set_xticklabels(xlab, fontsize=8)\n",
    "# _ = ax.set_xticklabels(fontsize=8)\n",
    "_ = ax.set_xlabel('Mean number of samples with nonzero counts across KOs in taxid')\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot n contigs vs nkos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_counts = []\n",
    "c_counts = []\n",
    "for n in tree.traverse():\n",
    "    c_counts.append(n.props['n_contigs'])\n",
    "    k_counts.append(n.props['nkos'])\n",
    "\n",
    "fig, ax = general_plot()\n",
    "ax.scatter(k_counts, c_counts, alpha=0.25)\n",
    "_ = ax.set_xlabel('Number of KOs')\n",
    "_ = ax.set_ylabel('Number of contigs')\n",
    "_ = ax.set_yscale('log')\n",
    "_ = ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim leaves based on loose filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim taxids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_n_contigs = 30\n",
    "thresh_nkos = 30\n",
    "\n",
    "taxids_trim = []\n",
    "for n in tree.leaves():\n",
    "    nc = n.props['n_contigs']\n",
    "    nk = n.props['nkos']\n",
    "    tid = n.name\n",
    "    ancest = n.ancestors()\n",
    "    while (nc < thresh_n_contigs) or (nk < thresh_nkos):\n",
    "        n_a = next(ancest)\n",
    "        nc = n_a.props['n_contigs']\n",
    "        nk = n_a.props['nkos']\n",
    "        tid = n_a.name            \n",
    "    taxids_trim.append(tid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_trim = ncbi.get_topology(taxids_trim)\n",
    "\n",
    "for n in tree_trim.traverse():\n",
    "    l = n.name\n",
    "    n_contigs = dict_tax_contigcount[int(l)]\n",
    "    max_n_sam, meam_n_sam = dict_lin_maxmeannsam[l]\n",
    "    nkos = dict_lin_nkos[l]\n",
    "    n.add_props(\n",
    "        n_contigs=n_contigs, \n",
    "        max_n_sam=max_n_sam, \n",
    "        mean_n_sam=mean_n_sam, \n",
    "        nkos=nkos\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_trim.to_str(props=['sci_name','n_contigs','nkos','max_n_sam'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction of contigs with these leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_count = 0\n",
    "for n in tree_trim.leaves():\n",
    "    c_count += n.props['n_contigs']\n",
    "\n",
    "total_n_contigs = len(taxids_all)\n",
    "\n",
    "frac = c_count / total_n_contigs\n",
    "c_count, frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each node, what is the fraction of contigs with this as their finest rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tree_trim.traverse():\n",
    "    nc_current = n.props['n_contigs']\n",
    "    nc_descend = 0\n",
    "    for n_d in n.get_children():\n",
    "        nc_descend += n_d.props['n_contigs']\n",
    "    n.add_props(\n",
    "        frac_finest = round(1 - nc_descend / nc_current, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_trim.to_str(props=['sci_name','n_contigs', 'frac_finest'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many taxids do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_taxids_trim = len(list(tree_trim.traverse()))\n",
    "n_taxids_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign trimmed taxonomy to contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full set of taxids in the trimmmed tree\n",
    "set_taxids_trim = set(n.name for n in tree_trim.traverse())\n",
    "\n",
    "# Set up a new taxon mapping\n",
    "dict_contig_taxtrim = {}\n",
    "for c, t in dict_contig_tax.items():\n",
    "    t = t[0]\n",
    "    if int(t):\n",
    "        # If there's no need to trim this taxid\n",
    "        if t in set_taxids_trim:\n",
    "            dict_contig_taxtrim[c] = t\n",
    "        else:\n",
    "            # If the taxid exists in the ncbi database\n",
    "            try:\n",
    "                ancest = iter([str(l) for l in  ncbi.get_lineage(t)][::-1])\n",
    "                too_low = 1\n",
    "                # Step back through ancestors\n",
    "                while too_low:\n",
    "                    ta = next(ancest)\n",
    "                    if ta in set_taxids_trim:\n",
    "                        dict_contig_taxtrim[c] = ta\n",
    "                        too_low = 0\n",
    "            except:\n",
    "                pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim leaves based on strict filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim taxids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_n_contigs = 30\n",
    "thresh_nkos = 90\n",
    "\n",
    "taxids_trim = []\n",
    "for n in tree.leaves():\n",
    "    nc = n.props['n_contigs']\n",
    "    nk = n.props['nkos']\n",
    "    tid = n.name\n",
    "    ancest = n.ancestors()\n",
    "    while (nc < thresh_n_contigs) or (nk < thresh_nkos):\n",
    "        n_a = next(ancest)\n",
    "        nc = n_a.props['n_contigs']\n",
    "        nk = n_a.props['nkos']\n",
    "        tid = n_a.name            \n",
    "    taxids_trim.append(tid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_trim = ncbi.get_topology(taxids_trim)\n",
    "\n",
    "for n in tree_trim.traverse():\n",
    "    l = n.name\n",
    "    n_contigs = dict_tax_contigcount[int(l)]\n",
    "    max_n_sam, meam_n_sam = dict_lin_maxmeannsam[l]\n",
    "    nkos = dict_lin_nkos[l]\n",
    "    n.add_props(\n",
    "        n_contigs=n_contigs, \n",
    "        max_n_sam=max_n_sam, \n",
    "        mean_n_sam=mean_n_sam, \n",
    "        nkos=nkos\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_trim.to_str(props=['sci_name','n_contigs','nkos','max_n_sam'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction of contigs with these leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_count = 0\n",
    "for n in tree_trim.leaves():\n",
    "    c_count += n.props['n_contigs']\n",
    "\n",
    "total_n_contigs = len(taxids_all)\n",
    "\n",
    "frac = c_count / total_n_contigs\n",
    "c_count, frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each node, what is the fraction of contigs with this as their finest rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tree_trim.traverse():\n",
    "    nc_current = n.props['n_contigs']\n",
    "    nc_descend = 0\n",
    "    for n_d in n.get_children():\n",
    "        nc_descend += n_d.props['n_contigs']\n",
    "    n.add_props(\n",
    "        frac_finest = round(1 - nc_descend / nc_current, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_trim.to_str(props=['sci_name','n_contigs', 'frac_finest'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many taxids do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_taxids_trim = len(list(tree_trim.traverse()))\n",
    "n_taxids_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign trimmed taxonomy to contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full set of taxids in the trimmmed tree\n",
    "set_taxids_trim = set(n.name for n in tree_trim.traverse())\n",
    "\n",
    "# Set up a new taxon mapping\n",
    "dict_contig_taxtrim = {}\n",
    "for c, t in dict_contig_tax.items():\n",
    "    t = t[0]\n",
    "    if int(t):\n",
    "        # If there's no need to trim this taxid\n",
    "        if t in set_taxids_trim:\n",
    "            dict_contig_taxtrim[c] = t\n",
    "        else:\n",
    "            # If the taxid exists in the ncbi database\n",
    "            try:\n",
    "                ancest = iter([str(l) for l in  ncbi.get_lineage(t)][::-1])\n",
    "                too_low = 1\n",
    "                # Step back through ancestors\n",
    "                while too_low:\n",
    "                    ta = next(ancest)\n",
    "                    if ta in set_taxids_trim:\n",
    "                        dict_contig_taxtrim[c] = ta\n",
    "                        too_low = 0\n",
    "            except:\n",
    "                pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map node name to contig list (contigs that don't map to a lower node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_taxtrim_contigs = defaultdict(list)\n",
    "for c, t in dict_contig_taxtrim.items():\n",
    "    dict_taxtrim_contigs[t].append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get nkos at each node (not including children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tree_trim.traverse():\n",
    "    contigs = dict_taxtrim_contigs[n.name]\n",
    "    kos = [dict_contig_ko[c] for c in contigs]\n",
    "    n.add_props(\n",
    "        nkos_nochild=len(set(kos))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree_trim.to_str(props=['sci_name','nkos_nochild'], compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build slabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dict contig -> sample est counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of sample names\n",
    "dir_counts = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/dicts_iron_KO_contig/dicts_contig_count'\n",
    "glob_fn = f'{dir_counts}/*G1PA*3um*.json'\n",
    "fns = glob.glob(glob_fn)\n",
    "fns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnf.getmem()\n",
    "dict_contig_estcounts = defaultdict(list)\n",
    "contigs_all = list(dict_contig_tax.keys())\n",
    "samples = []\n",
    "for fn in fns:\n",
    "    if '_3um' in fn:\n",
    "        samples.append(re.search(r'(?<=.tar.gz).+(?=\\.tsv-)', fn)[0])\n",
    "        # Load counts\n",
    "        with open(fn, 'r') as f:\n",
    "            dict_ctg_cnt = json.load(f)\n",
    "        for c in contigs_all:\n",
    "            c_ = re.sub(r'_\\d+$','',c)\n",
    "            # map contig to counts\n",
    "            dict_contig_estcounts[c].append(float(dict_ctg_cnt[c_][0]))\n",
    "fnf.getmem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[c, dict_contig_estcounts[c]] for c in contigs_all[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many kos are in each sample across the nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_sam_kos = defaultdict(lambda: defaultdict(set))\n",
    "for n in tree_trim.traverse():\n",
    "    contigs = dict_taxtrim_contigs[n.name]\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        estcounts = dict_contig_estcounts[c]\n",
    "        for sam, ec in enumerate(estcounts):\n",
    "            if ec:\n",
    "                dict_tax_sam_kos[n.name][sam].add(ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot(dims=(10,4))\n",
    "\n",
    "xlab = []\n",
    "\n",
    "for x_, n in enumerate(tree_trim.traverse()):\n",
    "    nkos = []\n",
    "    for _, kos in dict_tax_sam_kos[n.name].items():\n",
    "        nkos.append(len(kos))\n",
    "    x = np.repeat(x_, len(nkos)).astype(float) \n",
    "    x += (np.random.rand(x.shape[0]) - 0.5) * 0.25\n",
    "    ax.scatter(x, np.array(nkos), c='k', s=2)\n",
    "    xlab.append(n.props['sci_name'])\n",
    "\n",
    "ax.set_xticks(np.arange(x_+1))\n",
    "ax.set_xticklabels(xlab, rotation=45, size=ft, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylabel('Numer of KOs in sample')\n",
    "ax.set_xlabel('Taxid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim again, removing levels with low mean number of kos in sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_nkos(contigs):\n",
    "    dict_sam_kos = defaultdict(set)\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        estcounts = dict_contig_estcounts[c]\n",
    "        for sam, ec in enumerate(estcounts):\n",
    "            if ec:\n",
    "                dict_sam_kos[sam].add(ko)\n",
    "    nkos = []\n",
    "    for _, kos in dict_sam_kos.items():\n",
    "        nkos.append(len(kos))\n",
    "    return np.mean(nkos)\n",
    "\n",
    "filt_mean_nkos = 30\n",
    "\n",
    "taxids_trim2 = []\n",
    "dict_taxtrim2_contigs = defaultdict(list)\n",
    "# Traverse from leaves to root\n",
    "for n in tree_trim.traverse(strategy='postorder'):\n",
    "    tid = n.name\n",
    "    # Get any new contigs from children\n",
    "    if tid in dict_taxtrim2_contigs:\n",
    "        contigs = dict_taxtrim2_contigs[tid]\n",
    "    # Otherwise get old contigs for node\n",
    "    else:\n",
    "        contigs = dict_taxtrim_contigs[tid]\n",
    "    # skip if root node\n",
    "    if not n.is_root:\n",
    "        # if the mean nkos is less than desired\n",
    "        mean_nkos = get_mean_nkos(contigs)\n",
    "        if mean_nkos < filt_mean_nkos:\n",
    "            print(n.props['sci_name'], tid)\n",
    "            # Then add these contigs to the parent taxon id\n",
    "            tid_parent = next(n.ancestors()).name\n",
    "            if tid_parent in dict_taxtrim2_contigs:\n",
    "                dict_taxtrim2_contigs[tid_parent] += contigs\n",
    "            else:\n",
    "                contigs_parent = dict_taxtrim_contigs[tid_parent]\n",
    "                dict_taxtrim2_contigs[tid_parent] += contigs_parent + contigs\n",
    "            # Remove existing taxid mapping\n",
    "            if tid in dict_taxtrim2_contigs:\n",
    "                del dict_taxtrim2_contigs[tid]\n",
    "        else:\n",
    "            dict_taxtrim2_contigs[tid] = contigs\n",
    "    else:\n",
    "        dict_taxtrim2_contigs[tid] = contigs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxids_trim2 = list(dict_taxtrim2_contigs.keys())\n",
    "len(taxids_trim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_trim2 = ncbi.get_topology(taxids_trim2)\n",
    "\n",
    "print(tree_trim2.to_str(props=['sci_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how many kos are in each sample across the nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_sam_kos = defaultdict(lambda: defaultdict(set))\n",
    "for n in tree_trim2.traverse():\n",
    "    contigs = dict_taxtrim2_contigs[n.name]\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        estcounts = dict_contig_estcounts[c]\n",
    "        for sam, ec in enumerate(estcounts):\n",
    "            if ec:\n",
    "                dict_tax_sam_kos[n.name][sam].add(ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot(dims=(10,4))\n",
    "\n",
    "xlab = []\n",
    "\n",
    "for x_, n in enumerate(tree_trim2.traverse()):\n",
    "    nkos = []\n",
    "    for _, kos in dict_tax_sam_kos[n.name].items():\n",
    "        nkos.append(len(kos))\n",
    "    x = np.repeat(x_, len(nkos)).astype(float) \n",
    "    x += (np.random.rand(x.shape[0]) - 0.5) * 0.25\n",
    "    ax.scatter(x, np.array(nkos), c='k', s=2)\n",
    "    ax.plot([x_-0.25, x_+0.25],[np.mean(nkos)]*2, 'r')\n",
    "    xlab.append(n.props['sci_name'])\n",
    "\n",
    "xlims = ax.get_xlim()\n",
    "ax.plot(xlims,[filt_mean_nkos]*2, 'k:')\n",
    "\n",
    "ax.set_xticks(np.arange(x_+1))\n",
    "ax.set_xticklabels(xlab, rotation=45, size=ft, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylabel('Numer of KOs in sample')\n",
    "ax.set_xlabel('Taxid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples are in each ko across the nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_ko_sams = defaultdict(lambda: defaultdict(set))\n",
    "for n in tree_trim.traverse():\n",
    "    contigs = dict_taxtrim_contigs[n.name]\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        estcounts = dict_contig_estcounts[c]\n",
    "        for sam, ec in enumerate(estcounts):\n",
    "            if ec:\n",
    "                dict_tax_ko_sams[n.name][ko].add(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot(dims=(10,4))\n",
    "\n",
    "xlab = []\n",
    "\n",
    "for x_, n in enumerate(tree_trim.traverse()):\n",
    "    nkos = []\n",
    "    for _, kos in dict_tax_ko_sams[n.name].items():\n",
    "        nkos.append(len(kos))\n",
    "    x = np.repeat(x_, len(nkos)).astype(float) \n",
    "    x += (np.random.rand(x.shape[0]) - 0.5) * 0.25\n",
    "    ax.scatter(x, np.array(nkos), c='k', s=2)\n",
    "    xlab.append(n.props['sci_name'])\n",
    "\n",
    "ax.set_xticks(np.arange(x_+1))\n",
    "ax.set_xticklabels(xlab, rotation=45, size=ft, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylabel('Numer of samples in KO')\n",
    "ax.set_xlabel('Taxid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get slab dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_ko_estcounts = defaultdict(lambda: defaultdict(list))\n",
    "for n in tree_trim2.traverse():\n",
    "    contigs = dict_taxtrim2_contigs[n.name]\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        dict_tax_ko_estcounts[n.name][ko].append(\n",
    "            dict_contig_estcounts[c]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_slab = {}\n",
    "for n in tree_trim2.traverse():\n",
    "    # Add counts for all contigs in KO across samples\n",
    "    dict_ko_sumestcounts = {\n",
    "        ko: np.sum(ec, axis=0) \n",
    "        for ko, ec in dict_tax_ko_estcounts[n.name].items()\n",
    "    }\n",
    "    dict_tax_slab[n.name] = pd.DataFrame(\n",
    "        dict_ko_sumestcounts,\n",
    "        index=samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax = np.random.choice(taxids_trim2)\n",
    "dict_tax_slab[tax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove samples with few KOs and remove kos with few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_nkos = 20\n",
    "thresh_nsam = 3\n",
    "\n",
    "dict_tax_slab_filt = {}\n",
    "for n in tree_trim2.traverse():\n",
    "    df = dict_tax_slab[n.name]\n",
    "    dfb = df.astype(bool)\n",
    "    nkos = dfb.sum(axis=1)\n",
    "    nsam = dfb.sum(axis=0)\n",
    "    bool_nkos = nkos > thresh_nkos\n",
    "    bool_nsam = nsam > thresh_nsam\n",
    "    df_filt = df.loc[bool_nkos, bool_nsam]\n",
    "    dict_tax_slab_filt[n.name] = df_filt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/scratch/bgrodner/iron_ko_contigs/metat_search_results/barnacle/G1PA/3um'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for n in tree_trim2.traverse():\n",
    "    df = dict_tax_slab_filt[n.name]\n",
    "    out_fn = f'{out_dir}/taxon_slabs/G1PA_3um-taxid_{n.name}-df_estcounts_sample_ko.csv'\n",
    "    df.to_csv(out_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tidy format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse filenames function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn_kallisto_sn(fn, sn_type='', get_columns=False):\n",
    "    if not get_columns:\n",
    "        try:\n",
    "            ass, sample, ammend, timep, depth, size, rep = [''] * 7\n",
    "            if sn_type == 'G1NS':\n",
    "                ass, sm_sz, rep, _ = fn.split('.')\n",
    "                sample, sz = sm_sz.split('_',1)\n",
    "                size = re.sub('_','.',sz)\n",
    "            elif sn_type == 'G2NS':\n",
    "                ass, sample, depth, sz, rep, _ = fn.split('.')\n",
    "                size = re.sub('_','.',sz)\n",
    "            elif sn_type == 'G3NS':\n",
    "                ass_sm, dp_sz_rep = fn.split('_', 1)\n",
    "                ass = re.match(r'.+NS', ass_sm)[0]\n",
    "                sample = re.search(r'UW\\d+', ass_sm)[0]\n",
    "                dp1, dp2, sz, rep, _ = dp_sz_rep.split('.')\n",
    "                depth = f'{dp1}.{dp2}'\n",
    "                size = re.sub('_','.',sz)\n",
    "            elif sn_type == 'G5':\n",
    "                ass, sample, ammend, timep, rep, _ = fn.split('.')\n",
    "            elif sn_type == 'D1':\n",
    "                ass, sm_rep_tp, _, _ = fn.split('.')\n",
    "                sample, rep, timep = sm_rep_tp.split('_')\n",
    "            elif sn_type == 'G1PA':\n",
    "                ass, fn_ = fn.split('.', 1)\n",
    "                sample, fn_ = fn_.split('_', 1)\n",
    "                size = re.search(r'.+um', fn_)[0]\n",
    "                rep = re.search(r'(?<=um)\\w+(?=\\.)',fn_)[0]\n",
    "            elif sn_type == 'G2PA':\n",
    "                _, ass, sample, depth, sz, rep, _, _ = fn.split('.')\n",
    "                size = re.sub('_','.',sz)\n",
    "            elif sn_type == 'G3PA.UW':\n",
    "                ass, sample, _, _, _, _ = fn.split('.')\n",
    "            elif sn_type == 'G3PA.diel':\n",
    "                ass1, ass2, sample, rep, _, _, _, _ = fn.split('.')\n",
    "                ass = f'{ass1}.{ass2}'\n",
    "            elif sn_type == 'G3PA.PM':\n",
    "                ass_sm, dp_tp_sz_rp = fn.split('_', 1)\n",
    "                ass = re.match(r'.+(?=.UW)', ass_sm)[0]\n",
    "                sample = re.search(r'UW\\d+$', ass_sm)[0]\n",
    "                depth, tp_sz_rp = dp_tp_sz_rp.split('_',1)\n",
    "                timep, sz_rp = tp_sz_rp.split('.',1)\n",
    "                size = re.match(r'.+um(?=\\.)', sz_rp)[0]\n",
    "                rep = re.search(r'(?<=um\\.)\\w+', sz_rp)[0]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"\"\"\n",
    "                    Sample name parse type not provided (sn_type_parse_kallisto column in file table)\n",
    "                    \"\"\"\n",
    "                )        \n",
    "            return [ass, sample, ammend, timep, depth, size, rep]\n",
    "        except:\n",
    "            raise ValueError(\n",
    "                f\"\"\"\n",
    "                Failed to parse filename:\n",
    "                {fn}\n",
    "                Using type:\n",
    "                {sn_type}\n",
    "                \"\"\"\n",
    "            )\n",
    "    else:\n",
    "        return ['assembly', 'sample', 'ammendment', 'timepoint', 'depth', 'size', 'rep']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fn_kallisto_sn(samples[0][1:], sn_type='G1PA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build tidy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = []\n",
    "columns = ['gene','taxon','sample','replicate','transcript_count']\n",
    "for tax, dict_ko_estcounts in dict_tax_ko_estcounts.items():\n",
    "    for ko, estcounts in dict_ko_estcounts.items():\n",
    "        ec_sum = np.sum(estcounts, axis=0)\n",
    "        for sn, count in zip(samples, ec_sum):\n",
    "            ass, sample, _, _, _, size, rep = (\n",
    "                parse_fn_kallisto_sn(sn[1:], sn_type='G1PA')\n",
    "            )\n",
    "            row = [ko, tax, sample, rep, count]\n",
    "            tidy_df.append(row)\n",
    "\n",
    "tidy_df = pd.DataFrame(tidy_df, columns=columns)\n",
    "tidy_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save tidy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = f'{out_dir}/G1PA_3um-df_tidy_estcounts.csv'\n",
    "tidy_df.to_csv(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3],[1,2,3]]\n",
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(a,b):\n",
    "    return a+b\n",
    "\n",
    "def c(a,b,c):\n",
    "    return a-b-c\n",
    "\n",
    "def b(x, **args):\n",
    "    if x > 0:\n",
    "        return a(**args)\n",
    "    elif x:\n",
    "        return c(**args)\n",
    "b(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the TreeTrim class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.cl_tree_trim import TreeTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_tidy = 'metat_search_results/dicts_iron_KO_contig/tidy_tables/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tidys/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tidy.csv'\n",
    "# test = TreeTrim(fn_tidy)\n",
    "test = TreeTrim(dict_contig_tax, dict_contig_ko, dict_contig_estcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.tree.to_str(props=['sci_name', 'name'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.trim_tree('nkos_in_gt_minsamples', thresh=30, minsamples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.treetrim.to_str(props=['sci_name'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tax_sam_kos = defaultdict(lambda: defaultdict(set))\n",
    "for n in test.treetrim.traverse():\n",
    "    contigs = test.dict_taxtrim_contigs[n.name]\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        estcounts = dict_contig_estcounts[c]\n",
    "        for sam, ec in enumerate(estcounts):\n",
    "            if ec:\n",
    "                dict_tax_sam_kos[n.name][sam].add(ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = general_plot(dims=(10,4))\n",
    "\n",
    "xlab = []\n",
    "\n",
    "thresh = 30\n",
    "ft = 5\n",
    "for x_, n in enumerate(test.treetrim.traverse()):\n",
    "    nkos = []\n",
    "    for _, kos in dict_tax_sam_kos[n.name].items():\n",
    "        nkos.append(len(kos))\n",
    "    x = np.repeat(x_, len(nkos)).astype(float) \n",
    "    x += (np.random.rand(x.shape[0]) - 0.5) * 0.25\n",
    "    ax.scatter(x, np.array(nkos), c='k', s=2)\n",
    "    ax.plot([x_-0.25, x_+0.25],[np.mean(nkos)]*2, 'r')\n",
    "    xlab.append(n.props['sci_name'])\n",
    "\n",
    "xlims = ax.get_xlim()\n",
    "ax.plot(xlims,[thresh]*2, 'k:')\n",
    "\n",
    "ax.set_xticks(np.arange(x_+1))\n",
    "ax.set_xticklabels(xlab, rotation=45, size=ft, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylabel('Numer of KOs in sample')\n",
    "ax.set_xlabel('Taxid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the distribution of nkos across sample and nsamples across ko?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos_all = list(dict_ko_contigs.keys())\n",
    "nsam = len(list(dict_contig_estcounts.values())[0])\n",
    "\n",
    "nsam, len(kos_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_pos = '35677' # Pelagomonas calceolata\n",
    "tid_neg = '2802065' # Chrysochromulina sp. KB-HA01\n",
    "\n",
    "\n",
    "for tid in [tid_pos, tid_neg]:\n",
    "    print(ncbi.get_taxid_translator([tid])[int(tid)])\n",
    "    contigs = dict_tax_contigs[tid]\n",
    "    print(len(contigs), 'contigs')\n",
    "    dict_ko_estcounts = {}\n",
    "    for c in contigs:\n",
    "        ko = dict_contig_ko[c]\n",
    "        estcounts = dict_contig_estcounts[c]\n",
    "        estcounts = np.array(estcounts)\n",
    "        if ko in dict_ko_estcounts:\n",
    "            dict_ko_estcounts[ko] += estcounts\n",
    "        else:\n",
    "            dict_ko_estcounts[ko] = estcounts\n",
    "    estc_list = []\n",
    "    for ko in kos_all:\n",
    "        if ko in dict_ko_estcounts:\n",
    "            estc_list.append(dict_ko_estcounts[ko])\n",
    "        else:\n",
    "            estc_list.append(np.zeros(nsam))\n",
    "    estc_arr = np.array(estc_list)\n",
    "\n",
    "    estc_bool = estc_arr.astype(bool)\n",
    "    ax1_sum = estc_bool.sum(axis=1)\n",
    "    ax0_sum = estc_bool.sum(axis=0)\n",
    "\n",
    "    fig, ax = general_plot()\n",
    "    _ = ax.hist(ax0_sum, bins=20)\n",
    "    _ = ax.set_xlabel('Number of nonzero KOs')\n",
    "    _ = ax.set_ylabel('Number of samples')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = general_plot()\n",
    "    _ = ax.hist(ax1_sum, bins=20)\n",
    "    _ = ax.set_xlabel('Number of nonzero samples')\n",
    "    _ = ax.set_ylabel('Number of KOs')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True + True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(dict_contig_estcounts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = defaultdict(lambda: np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['a'] += np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictofdicts = defaultdict(dict)\n",
    "for contig, tax in dict_contig_tax.items():\n",
    "    ko = dict_contig_ko[contig]\n",
    "    estcounts = dict_contig_estcounts[contig]\n",
    "    dictofdicts[contig]['tax'] = tax\n",
    "    dictofdicts[contig]['ko'] = ko\n",
    "    dictofdicts[contig]['estcounts'] = estcounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:20]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_13.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dict_contig_tax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig_tax['G1PA_S02C1_0_2um_TRINITY_DN1001023_c0_g1_i1_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.ncbi.get_name_translator('Pelagomonas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'a':[1,'',3],'b':[4,5,6]})\n",
    "b = a.loc[a.a == 2].squeeze()\n",
    "b.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "del TreeTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tidy = 'tidytest.csv'\n",
    "# fn_tidy = 'metat_search_results/dicts_iron_KO_contig/tidy_tables/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tidys/NPac.G1PA.bf100.id99.aa.best.Kofam.incT30.csv.gz-iron_KOs.txt-tidy.csv'\n",
    "\n",
    "os.path.exists(fn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "del t\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.cl_tree_trim_02 import TreeTrim\n",
    "\n",
    "t = TreeTrim(fn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.trim_tree(\n",
    "    filt_func_name='nkos_in_gt_minsamples',\n",
    "    thresh=30,\n",
    "    minsamples=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.tree.to_str(props=['sci_name', 'name'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.treetrim.to_str(props=['sci_name', 'name'], compact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigs = t.dict_taxtrim_contigs['226']  # Alteromonas\n",
    "dict_ko_sam_estcounts = defaultdict(lambda: \n",
    "    defaultdict(float)\n",
    ")\n",
    "for c in contigs:\n",
    "    ko = t.dict_contig[t.col_ko][c]\n",
    "    sams = t.dict_contig[t.col_sample][c]\n",
    "    estcounts = t.dict_contig[t.col_estcounts][c]\n",
    "    for s, ec in zip(sams, estcounts):\n",
    "        dict_ko_sam_estcounts[ko][s] += float(ec)\n",
    "\n",
    "len(dict_ko_sam_estcounts), next(iter(dict_ko_sam_estcounts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkos = 0\n",
    "kos = []\n",
    "for ko, dict_sam_estcounts in dict_ko_sam_estcounts.items():\n",
    "    ko_in_nsam = 0\n",
    "    for _, ec in dict_sam_estcounts.items():\n",
    "        ko_in_nsam += bool(ec)\n",
    "    if ko_in_nsam >= 4:\n",
    "        nkos += 1\n",
    "        kos.append(ko)\n",
    "len(kos), nkos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ko_sam_estcounts[kos[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at distribution of kos in two examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_pos = '35677' # Pelagomonas calceolata\n",
    "tid_neg = '418951' # Isochrysidaceae\n",
    "tid_neg2 = '1035538' # mamiellophyceae\n",
    "\n",
    "tids = [tid_pos, tid_neg, tid_neg2]\n",
    "\n",
    "\n",
    "kos_all = set(list(t.dict_contig[t.col_ko].values()))\n",
    "sams_all = set([s for ss in t.dict_contig[t.col_sample].values() for s in ss])\n",
    "for tid in tids:\n",
    "    print(ncbi.get_taxid_translator([tid])[int(tid)])\n",
    "    contigs = t.dict_taxon_contigs[tid]\n",
    "    print(len(contigs), 'contigs')\n",
    "    dict_ko_sam_estcounts = defaultdict(lambda: defaultdict(float))\n",
    "    for c in contigs:\n",
    "        ko = t.dict_contig[t.col_ko][c]\n",
    "        estcounts = t.dict_contig[t.col_estcounts][c]\n",
    "        sams = t.dict_contig[t.col_sample][c]\n",
    "        for ec, s in zip(estcounts, sams):\n",
    "            dict_ko_sam_estcounts[ko][s] += float(ec)\n",
    "    ec_ko_list = []\n",
    "    for ko in kos_all:\n",
    "        if ko in dict_ko_sam_estcounts:\n",
    "            ec_sam_list = []\n",
    "            for s in sams_all:\n",
    "                ec_sam_list.append(dict_ko_sam_estcounts[ko].get(s,0))\n",
    "            ec_ko_list.append(np.array(ec_sam_list))\n",
    "        else:\n",
    "            ec_ko_list.append(np.zeros(len(sams_all)))\n",
    "    estc_arr = np.array(ec_ko_list)\n",
    "\n",
    "    estc_bool = estc_arr.astype(bool)\n",
    "    ax1_sum = estc_bool.sum(axis=1)\n",
    "    ax0_sum = estc_bool.sum(axis=0)\n",
    "\n",
    "    fig, ax = general_plot()\n",
    "    _ = ax.hist(ax0_sum, bins=20)\n",
    "    _ = ax.set_xlabel('Number of nonzero KOs')\n",
    "    _ = ax.set_ylabel('Number of samples')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = general_plot()\n",
    "    _ = ax.hist(ax1_sum, bins=30)\n",
    "    _ = ax.set_xlabel('Number of nonzero samples')\n",
    "    _ = ax.set_ylabel('Number of KOs')\n",
    "    _ = ax.set_yscale('log')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.fn_metat_files as fnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = fn_tidy\n",
    "col_key = 'contig'\n",
    "cols_val = ['KO', 'taxon', 'estcounts', 'sample']\n",
    "cols_key2list = ['estcounts', 'sample']\n",
    "cols_key2value = ['KO','taxon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "\n",
    "fnf.getmem()\n",
    "with open(fn, 'r') as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    dict_out = defaultdict(lambda: defaultdict(list))\n",
    "    for dict_row in csv_reader:\n",
    "        key = dict_row[col_key]\n",
    "        for cv in cols_key2list:\n",
    "            dict_out[key][cv].append(dict_row[cv])\n",
    "        for cv in cols_key2value:\n",
    "            if not cv in dict_out[key]:\n",
    "                dict_out[key][cv] = dict_row[cv]\n",
    "\n",
    "    fnf.getmem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_out['G1PA_S02C1_0_2um_TRINITY_DN1020701_c0_g1_i1_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dict_out\n",
    "gc.collect()\n",
    "fnf.getmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnf.getmem()\n",
    "with open(fn, 'r') as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    dict_out = defaultdict(list)\n",
    "    for dict_row in csv_reader:\n",
    "        key = dict_row[col_key]\n",
    "        if not key in dict_out:\n",
    "            for cv in cols_key2value:\n",
    "                dict_out[key].append(dict_row[cv])\n",
    "        for cv in cols_key2list:\n",
    "            dict_out[key].append(dict_row[cv])\n",
    "\n",
    "    fnf.getmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dict_out\n",
    "gc.collect()\n",
    "fnf.getmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnf.getmem()\n",
    "\n",
    "cols_key2list = ['estcounts', 'sample']\n",
    "cols_key2value = ['KO','taxon']\n",
    "dicts_out_val = [{} for _ in cols_key2value]\n",
    "dicts_out_list = [defaultdict(list) for _ in cols_key2list]\n",
    "\n",
    "with open(fn, 'r') as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    for dict_row in csv_reader:\n",
    "        k = dict_row[col_key]\n",
    "        for i, v in enumerate(cols_key2value):\n",
    "            dicts_out_val[i][k] = dict_row[v]\n",
    "        for i, v in enumerate(cols_key2list):\n",
    "            dicts_out_list[i][k].append(dict_row[v])\n",
    "\n",
    "fnf.getmem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_out_val[0]['G1PA_S02C1_0_2um_TRINITY_DN1020701_c0_g1_i1_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dicts_out_list, dicts_out_val\n",
    "gc.collect()\n",
    "fnf.getmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dict_out.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "not 'G1PA_S02C1_0_2um_TRINITY_DN1020701_c0_g1_i1_3' in dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_out['G1PA_S02C1_0_2um_TRINITY_DN1020701_c0_g1_i1_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnf.getmem()\n",
    "dict_contig = fnf.tidytable_to_dict(fn, col_key, cols_val)\n",
    "fnf.getmem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(dict_contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(dict_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(dict_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn, 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    print(next(csv_reader, None))\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.isenabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig['G3PA.UW1_TRINITY_DN1000146_c1_g1_i1_1']['KO'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig_taxon = {}\n",
    "dict_contig_ko = {}\n",
    "dict_contig_estcounts = {}\n",
    "dict_contig_samples = {}\n",
    "for c, d in dict_contig.items():\n",
    "    dict_contig_taxon[c] = d['taxon'][0]\n",
    "    dict_contig_ko[c] = d['KO'][0]\n",
    "    dict_contig_estcounts[c] = d['estcounts']\n",
    "    dict_contig_samples[c] = d['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_contig_taxon['G3PA.UW1_TRINITY_DN1000146_c1_g1_i1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "notempty = 0\n",
    "empty = 0\n",
    "for c, ec in t.dict_contig_estcounts.items():\n",
    "    ec = [float(i) for i in ec]\n",
    "    if sum(ec) > 0:\n",
    "        notempty += 1\n",
    "    else:\n",
    "        empty += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "notempty, empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnf.getmem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fn.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'G3PA.UW60.unstranded.abundance.tsv.gz'\n",
    "input_table = pd.read_csv('file_table.240210.kofam_filt.csv', keep_default_na=False)\n",
    "meta_fn = input_table.loc[\n",
    "    input_table['name'] == 'G3PA.UW', \n",
    "    'fn_sample_metadata'\n",
    "].values[0]\n",
    "meta = pd.read_csv(meta_fn)\n",
    "ass, sample_, _, _, _, _ = fn.split('.')\n",
    "meta_sample = meta.loc[meta['Alias2'] == sample_, :]\n",
    "size = str(meta_sample['Filter'].values[0])\n",
    "depth = str(meta_sample['Depth'].values[0])\n",
    "rep = str(meta_sample['Replicate'].values[0])\n",
    "sample_list = str(meta_sample['Alias1'].values[0]).split(' ')\n",
    "sample = sample_list[0]\n",
    "if '#' in sample_list[1]:\n",
    "    sample += sample_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "size, depth, rep, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\n",
    "    'a':['1','2','3'],\n",
    "    'b':['4','5','6'], \n",
    "    'c':['7','8','9'],\n",
    "    'd':['7','8','9']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a.columns[(a.columns != \"a\") & (a.columns != \"d\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'abcde'\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = ['K04641', 'K03320', 'K16087', 'K19611', 'K01601', 'K02012',\n",
    "       'K15721', 'K02689', 'K02703', 'K00134', 'K00264', 'K18246',\n",
    "       'K03594', 'K04565', 'K03699', 'K05524', 'K01602', 'K02713',\n",
    "       'K08906', 'K01674']\n",
    "for ko in kos:\n",
    "    print(dict_ko_name[ko])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
